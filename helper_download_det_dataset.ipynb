{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/balandongiv/mmocr_tutorial/blob/main/helper_download_det_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MMOCR Tutorial\n",
        "\n",
        "Welcome to MMOCR! This is the **unofficial** colab tutorial for using MMOCR. In this tutorial, you will learn how to\n",
        "\n",
        "- Automatically download ocr public dataset that commonly used for training and validating tex detection and recognition.\n",
        "- Prepare mmocr-compatible annotation format\n",
        "\n",
        "Prepared by `Rodney Petrus Balandong`"
      ],
      "metadata": {
        "id": "CAYBkT6ZAd17"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxLc0Q53PzvS"
      },
      "source": [
        "# Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBEylsXZDCpE",
        "outputId": "17430ea6-e33f-470b-884c-b77d14cc2a4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:test\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n"
          ]
        }
      ],
      "source": [
        "!pip install wget\n",
        "import os\n",
        "from os.path import exists,isfile\n",
        "import requests\n",
        "import shutil\n",
        "import logging\n",
        "import wget\n",
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logging.info('test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAtwe5Xi0-yX"
      },
      "outputs": [],
      "source": [
        "# Install mmcv-full thus we could use CUDA operators\n",
        "!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu113/torch1.11.0/index.html\n",
        "\n",
        "# Install mmdetection\n",
        "!pip install mmdet\n",
        "\n",
        "# # Install mmocr\n",
        "!git clone https://github.com/open-mmlab/mmocr.git\n",
        "%cd mmocr\n",
        "!pip install -r requirements.txt\n",
        "!pip install -v -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoCtOL7dfnTz"
      },
      "outputs": [],
      "source": [
        "def check_dw(sfile,url,wget_dw=False):\n",
        "  if not isfile(sfile):\n",
        "      logging.info(f\"Downloading {os.path.split(sfile)[-1]} from\"\n",
        "                     f\" {url}.\")\n",
        "      if wget_dw:\n",
        "        wget.download(url, out=sfile)\n",
        "      else:\n",
        "        r = requests.get(url, verify=False,stream=True)  \n",
        "        with open(sfile, 'wb') as f:\n",
        "          f.write(r.content)\n",
        "def ch_make_folder(f):\n",
        "  if not os.path.exists(f):\n",
        "    os.makedirs(f)\n",
        "\n",
        "def move_files(source_dir,dest):\n",
        "  file_names = os.listdir(source_dir)\n",
        "  for file_name in file_names:\n",
        "    shutil.move(os.path.join(source_dir, file_name),dest)\n",
        "\n",
        "def move_files_to_des(file_names,dest):\n",
        "    for file_name in file_names:\n",
        "        shutil.move(file_name ,dest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcyfqRoFQgaO"
      },
      "source": [
        "# ICDAR 2011 (Born-Digital Images)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOo7ozKyTIn7"
      },
      "source": [
        "## [Text Recognition](https://mmocr.readthedocs.io/en/latest/datasets/recog.html#icdar-2011-born-digital-images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-12UAvM4JFvj",
        "outputId": "7c224193-9343-4830-a92d-7e5bbac853e3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Downloading Challenge1_Training_Task3_Images_GT.zip from https://rrc.cvc.uab.es/downloads/Challenge1_Training_Task3_Images_GT.zip.\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "INFO:root:Downloading Challenge1_Test_Task3_Images.zip from https://rrc.cvc.uab.es/downloads/Challenge1_Test_Task3_Images.zip.\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "INFO:root:Downloading Challenge1_Test_Task3_GT.txt from https://rrc.cvc.uab.es/downloads/Challenge1_Test_Task3_GT.txt.\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "INFO:root:Unpacking file\n",
            "INFO:root:Unpacking /content/drive/MyDrive/dataset/recognition/icdar2011/Challenge1_Training_Task3_Images_GT.zip to /content/drive/MyDrive/dataset/recognition/icdar2011/crops/train. \n",
            "INFO:root:Unpacking /content/drive/MyDrive/dataset/recognition/icdar2011/Challenge1_Test_Task3_Images.zip to /content/drive/MyDrive/dataset/recognition/icdar2011/crops/test. \n",
            "INFO:root:Move the annotation\n",
            "INFO:root:Generating grammar tables from /usr/lib/python3.7/lib2to3/Grammar.txt\n",
            "INFO:root:Generating grammar tables from /usr/lib/python3.7/lib2to3/PatternGrammar.txt\n",
            "INFO:root:Train split converted.\n",
            "INFO:root:Test split converted.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
          ]
        }
      ],
      "source": [
        "def icdar2011(npath,cleanup=False):\n",
        "    # Recognition\n",
        "    root=os.path.join(npath,'icdar2011')\n",
        "    dannot=os.path.join(root,'annotations')\n",
        "    dcrops=os.path.join(root,'crops')\n",
        "    dpath=dict(tr_img=dict(URL = \"https://rrc.cvc.uab.es/downloads/Challenge1_Training_Task3_Images_GT.zip\",\n",
        "                           fpath=os.path.join(root,'Challenge1_Training_Task3_Images_GT.zip')),\n",
        "               ts_img=dict(URL='https://rrc.cvc.uab.es/downloads/Challenge1_Test_Task3_Images.zip',\n",
        "                           fpath=os.path.join(root,'Challenge1_Test_Task3_Images.zip')),\n",
        "               ts_lbl=dict(URL='https://rrc.cvc.uab.es/downloads/Challenge1_Test_Task3_GT.txt',\n",
        "                           fpath=os.path.join(root,'Challenge1_Test_Task3_GT.txt'))\n",
        "               )\n",
        "\n",
        "\n",
        "\n",
        "    for dp in ([root,dcrops,dannot]):\n",
        "        ch_make_folder(dp)\n",
        "\n",
        "    for dp in (['tr_img','ts_img','ts_lbl']):\n",
        "        check_dw(dpath[dp]['fpath'],dpath[dp]['URL'])\n",
        "\n",
        "\n",
        "\n",
        "    dimg_tr=os.path.join(dcrops,'train')\n",
        "    dimg_ts=os.path.join(dcrops,'test')\n",
        "\n",
        "    logging.info(f'Unpacking file')\n",
        "\n",
        "    for dp, dirc_f in zip(['tr_img','ts_img'],\n",
        "                          [dimg_tr,dimg_ts]):\n",
        "        logging.info(f\"Unpacking {dpath[dp]['fpath']} to {dirc_f}. \")\n",
        "        shutil.unpack_archive(dpath[dp]['fpath'],dirc_f)\n",
        "\n",
        "\n",
        "    logging.info(f'Move the annotation')\n",
        "    fannot_ts=os.path.join(dannot,'Challenge1_Test_Task3_GT.txt')\n",
        "    shutil.move(dpath['ts_lbl']['fpath'],fannot_ts)\n",
        "\n",
        "\n",
        "    shutil.move(os.path.join(dimg_tr,'gt.txt'),\n",
        "                os.path.join(dannot,'Challenge1_Train_Task3_GT.txt'))\n",
        "\n",
        "    # Text Recognition\n",
        "    from tools.data.textrecog.ic11_converter import convert_annotations\n",
        "    format = 'jsonl'\n",
        "    for split in ['Train', 'Test']:\n",
        "        convert_annotations(root, split, format)\n",
        "        logging.info(f'{split} split converted.')\n",
        "\n",
        "    #     ├── icdar2011\n",
        "    # │   ├── crops\n",
        "    # │   ├── train_label.jsonl\n",
        "    # │   └── test_label.jsonl\n",
        "\n",
        "\n",
        "    ## Text Detection\n",
        "    if cleanup:\n",
        "        logging.info ('Cleaning up')\n",
        "        for dp in ['tr_img','ts_img']:\n",
        "            os.remove(dpath[dp]['fpath'])\n",
        "    \n",
        "\n",
        "icdar2011('/content/drive/MyDrive/dataset/recognition')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2biMYC3OCLb"
      },
      "source": [
        "## [Text Detection](https://mmocr.readthedocs.io/en/latest/datasets/det.html#icdar-2011-born-digital-images)\n",
        "ICDAR 2011 (Born-Digital Images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-BxpPo5OOKT"
      },
      "outputs": [],
      "source": [
        "def icdar2011(npath,cleanup=False):\n",
        "    # Detection\n",
        "    root=os.path.join(npath,'icdar2011')\n",
        "    dannot=os.path.join(root,'annotations')\n",
        "    dcrops=os.path.join(root,'imgs')\n",
        "    dpath=dict(tr_img=dict(URL = \"https://rrc.cvc.uab.es/downloads/Challenge1_Training_Task12_Images.zip\",\n",
        "                           fpath=os.path.join(root,'Challenge1_Training_Task12_Images.zip')),\n",
        "               tr_lbl=dict(URL='https://rrc.cvc.uab.es/downloads/Challenge1_Training_Task1_GT.zip',\n",
        "                           fpath=os.path.join(root,'Challenge1_Training_Task1_GT.zip')),\n",
        "               ts_img=dict(URL='https://rrc.cvc.uab.es/downloads/Challenge1_Test_Task12_Images.zip',\n",
        "                           fpath=os.path.join(root,'Challenge1_Test_Task12_Images.zip')),\n",
        "               ts_lbl=dict(URL='https://rrc.cvc.uab.es/downloads/Challenge1_Test_Task1_GT.zip',\n",
        "                           fpath=os.path.join(root,'Challenge1_Test_Task1_GT.zip')),\n",
        "               )\n",
        "\n",
        "\n",
        "    ch_make_folder(root)\n",
        "\n",
        "    for dp in (['tr_img','ts_img','ts_lbl','tr_lbl']):\n",
        "        check_dw(dpath[dp]['fpath'],dpath[dp]['URL'])\n",
        "\n",
        "\n",
        "\n",
        "    dimg_tr=os.path.join(dcrops,'training')\n",
        "    dimg_ts=os.path.join(dcrops,'test')\n",
        "    lbl_tr=os.path.join(dannot,'training')\n",
        "    lbl_ts=os.path.join(dannot,'test')\n",
        "\n",
        "    logging.info(f'Unpacking file')\n",
        "    for dp, dirc_f in zip(['tr_img','ts_img','tr_lbl','ts_lbl'],\n",
        "                          [dimg_tr,dimg_ts,lbl_tr,lbl_ts]):\n",
        "        logging.info(f\"Unpacking {dpath[dp]['fpath']} to {dirc_f}. \")\n",
        "        shutil.unpack_archive(dpath[dp]['fpath'],dirc_f)\n",
        "  \n",
        "    # Step 2: Generate instances_training.json and instances_test.json with the following command:\n",
        "\n",
        "    #python tools/data/textdet/ic11_converter.py PATH/TO/icdar2011 --nproc 4\n",
        "\n",
        "\n",
        "    import os.path as osp\n",
        "\n",
        "    import mmcv\n",
        "\n",
        "\n",
        "    from mmocr.utils import convert_annotations\n",
        "    from tools.data.textdet.ic11_converter import collect_files,collect_annotations\n",
        "    nproc=10\n",
        "\n",
        "    root_path =root\n",
        "\n",
        "    for split in ['training', 'test']:\n",
        "        print(f'Processing {split} set...')\n",
        "        with mmcv.Timer(print_tmpl='It takes {}s to convert annotation'):\n",
        "            files = collect_files(\n",
        "                osp.join(root_path, 'imgs', split),\n",
        "                osp.join(root_path, 'annotations', split))\n",
        "            image_infos = collect_annotations(files, nproc=nproc)\n",
        "            convert_annotations(\n",
        "                image_infos, osp.join(root_path,\n",
        "                                      'instances_' + split + '.json'))\n",
        "\n",
        "    #     │── icdar2011\n",
        "    # │   ├── imgs\n",
        "    # │   ├── instances_test.json\n",
        "    # │   └── instances_training.json\n",
        "\n",
        "\n",
        "    if cleanup:\n",
        "        logging.info ('Cleaning up')\n",
        "        for dp in ['tr_img','ts_img']:\n",
        "            os.remove(dpath[dp]['fpath'])\n",
        "\n",
        "\n",
        "icdar2011('/content/drive/MyDrive/dataset/detection')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4X8IvhGR6Gf"
      },
      "source": [
        "Step 2: Generate instances_training.json and instances_test.json with the following command:\n",
        "\n",
        "`python tools/data/textdet/ic11_converter.py PATH/TO/icdar2011 --nproc 4`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4-3tHmoQkt5"
      },
      "source": [
        "# ICDAR 2013 (Focused Scene Text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp8iFQ7hTun6"
      },
      "source": [
        "## [Text Recognition](https://mmocr.readthedocs.io/en/latest/datasets/recog.html#icdar-2013-deprecated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bp_6_MwYxRLg"
      },
      "outputs": [],
      "source": [
        "def icdar2013(npath,cleanup=False):\n",
        "    # Recognition\n",
        "    root=os.path.join(npath,'icdar2013')\n",
        "    dannot=os.path.join(root,'annotations')\n",
        "    dcrops=os.path.join(root,'crops')\n",
        "    dpath=dict(tr_img=dict(URL = \"https://rrc.cvc.uab.es/downloads/Challenge2_Training_Task3_Images_GT.zip\",\n",
        "                           fpath=os.path.join(root,'Challenge2_Training_Task3_Images_GT.zip')),\n",
        "               ts_img=dict(URL='https://rrc.cvc.uab.es/downloads/Challenge2_Test_Task3_Images.zip',\n",
        "                           fpath=os.path.join(root,'Challenge2_Test_Task3_Images.zip')),\n",
        "               ts_lbl=dict(URL='https://rrc.cvc.uab.es/downloads/Challenge2_Test_Task3_GT.txt',\n",
        "                           fpath=os.path.join(root,'Challenge2_Test_Task3_GT.txt'))\n",
        "               )\n",
        "\n",
        "    for dp in ([root,dcrops,dannot]):\n",
        "        ch_make_folder(dp)\n",
        "\n",
        "    for dp in (['tr_img','ts_img','ts_lbl']):\n",
        "        check_dw(dpath[dp]['fpath'],dpath[dp]['URL'])\n",
        "\n",
        "\n",
        "    dimg_tr=os.path.join(dcrops,'train')\n",
        "    dimg_ts=os.path.join(dcrops,'test')\n",
        "\n",
        "    logging.info(f'Unpacking file')\n",
        "\n",
        "    for dp, dirc_f in zip(['tr_img','ts_img'],\n",
        "                          [dimg_tr,dimg_ts]):\n",
        "        logging.info(f\"Unpacking {dpath[dp]['fpath']} to {dirc_f}. \")\n",
        "        shutil.unpack_archive(dpath[dp]['fpath'],dirc_f)\n",
        "\n",
        "\n",
        "    logging.info(f'Move the annotation')\n",
        "    fannot_ts=os.path.join(dannot,'Challenge2_Test_Task3_GT.txt')\n",
        "    shutil.move(dpath['ts_lbl']['fpath'],fannot_ts)\n",
        "\n",
        "    fannot_from=os.path.join(dimg_tr,'gt.txt')\n",
        "    fannot_tr=os.path.join(dannot,'Challenge2_Train_Task3_GT.txt')\n",
        "    shutil.move(fannot_from,fannot_tr)\n",
        "\n",
        "    format = 'jsonl'\n",
        "    from tools.data.textrecog.ic13_converter import convert_annotations\n",
        "    for split in ['Train', 'Test']:\n",
        "        convert_annotations(root, split, format)\n",
        "        print(f'{split} split converted.')\n",
        "\n",
        "\n",
        "    if cleanup:\n",
        "        logging.info ('Cleaning up')\n",
        "        for dp in ['tr_img','ts_img']:\n",
        "            os.remove(dpath[dp]['fpath'])\n",
        "\n",
        "\n",
        "    #   ├── icdar_2013\n",
        "    # │   ├── train_label.txt\n",
        "    # │   ├── test_label_1015.txt\n",
        "    # │   ├── test_label_1095.txt\n",
        "    # │   ├── Challenge2_Training_Task3_Images_GT\n",
        "    # │   └──  Challenge2_Test_Task3_Images         \n",
        "\n",
        "icdar2013('/content/drive/MyDrive/dataset/recognition')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL1RQFcpT15n"
      },
      "source": [
        "## [Text Detection](https://mmocr.readthedocs.io/en/latest/datasets/det.html#icdar-2013-focused-scene-text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zgkl8wpsyOzc"
      },
      "outputs": [],
      "source": [
        "def icdar2013(npath,cleanup=False):\n",
        "    # Detection\n",
        "    root=os.path.join(npath,'icdar2013')\n",
        "    dannot=os.path.join(root,'annotations')\n",
        "    dcrops=os.path.join(root,'imgs')\n",
        "    dpath=dict(tr_img=dict(URL = \"https://rrc.cvc.uab.es/downloads/Challenge2_Training_Task12_Images.zip\",\n",
        "                           fpath=os.path.join(root,'Challenge2_Training_Task12_Images.zip')),\n",
        "               ts_img=dict(URL='https://rrc.cvc.uab.es/downloads/Challenge2_Test_Task12_Images.zip',\n",
        "                           fpath=os.path.join(root,'Challenge2_Test_Task12_Images.zip')),\n",
        "               tr_lbl=dict(URL='https://rrc.cvc.uab.es/downloads/Challenge2_Training_Task1_GT.zip',\n",
        "                           fpath=os.path.join(root,'Challenge2_Training_Task1_GT.zip')),\n",
        "               ts_lbl=dict(URL='https://rrc.cvc.uab.es/downloads/Challenge2_Test_Task1_GT.zip',\n",
        "                           fpath=os.path.join(root,'Challenge2_Test_Task1_GT.zip')),\n",
        "               )\n",
        "\n",
        "\n",
        "    ch_make_folder(root)\n",
        "\n",
        "    for dp in (['tr_img','ts_img','ts_lbl','tr_lbl']):\n",
        "        check_dw(dpath[dp]['fpath'],dpath[dp]['URL'])\n",
        "\n",
        "\n",
        "\n",
        "    dimg_tr=os.path.join(dcrops,'training')\n",
        "    dimg_ts=os.path.join(dcrops,'test')\n",
        "    lbl_tr=os.path.join(dannot,'training')\n",
        "    lbl_ts=os.path.join(dannot,'test')\n",
        "\n",
        "    logging.info(f'Unpacking file')\n",
        "    for dp, dirc_f in zip(['tr_img','ts_img','tr_lbl','ts_lbl'],\n",
        "                          [dimg_tr,dimg_ts,lbl_tr,lbl_ts]):\n",
        "        logging.info(f\"Unpacking {dpath[dp]['fpath']} to {dirc_f}. \")\n",
        "        shutil.unpack_archive(dpath[dp]['fpath'],dirc_f)\n",
        "\n",
        "\n",
        "    # Step 2: Generate instances_training.json and instances_test.json with the following command:\n",
        "\n",
        "    # python tools/data/textdet/ic13_converter.py PATH/TO/icdar2013 --nproc 4\n",
        "\n",
        "\n",
        "    import mmcv\n",
        "\n",
        "    import os.path as osp\n",
        "    from mmocr.utils import convert_annotations\n",
        "    from tools.data.textdet.ic13_converter import collect_files,collect_annotations\n",
        "    nproc=10\n",
        "\n",
        "\n",
        "    root_path =root\n",
        "\n",
        "    for split in ['training', 'test']:\n",
        "        print(f'Processing {split} set...')\n",
        "        with mmcv.Timer(print_tmpl='It takes {}s to convert IC13 annotation'):\n",
        "            files = collect_files(\n",
        "                osp.join(root_path, 'imgs', split),\n",
        "                osp.join(root_path, 'annotations', split), split)\n",
        "            image_infos = collect_annotations(files, nproc=nproc)\n",
        "            convert_annotations(\n",
        "                image_infos, osp.join(root_path,\n",
        "                                      'instances_' + split + '.json'))\n",
        "\n",
        "\n",
        "    # │── icdar2013\n",
        "    # │   ├── imgs\n",
        "    # │   ├── instances_test.json\n",
        "    # │   └── instances_training.json\n",
        "\n",
        "\n",
        "icdar2013('/content/drive/MyDrive/dataset/detection')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leY9vVAsQnO2"
      },
      "source": [
        "# icdar2015"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nL7I6sGWRjZ"
      },
      "source": [
        "## [Text Recognition](https://mmocr.readthedocs.io/en/latest/datasets/recog.html#icdar-2015)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObU9jsZf0quq"
      },
      "outputs": [],
      "source": [
        "def icdar2015(npath,cleanup=False):\n",
        "    \"\"\"\n",
        "    # Recognition\n",
        "    Remark: icdar2015 does not have special python  converter\n",
        "    :param npath: \n",
        "    :param cleanup: \n",
        "    :return: \n",
        "    \"\"\"\n",
        "\n",
        "    root=os.path.join(npath,'icdar2015')\n",
        "    dts=os.path.join(root,'ch4_test_word_images_gt')\n",
        "    dtr=os.path.join(root,'ch4_training_word_images_gt')\n",
        "    dpath=dict(tr_img=dict(URL = \"https://rrc.cvc.uab.es/downloads/ch4_training_word_images_gt.zip\",\n",
        "                           fpath=os.path.join(root,'ch4_training_word_images_gt.zip')),\n",
        "               ts_img=dict(URL='https://rrc.cvc.uab.es/downloads/ch4_test_word_images_gt.zip',\n",
        "                           fpath=os.path.join(root,'ch4_test_word_images_gt.zip')),\n",
        "               # ts_lblx=dict(URL='https://rrc.cvc.uab.es/downloads/Challenge4_Test_Task3_GT.txt',\n",
        "               #              fpath=os.path.join(root,'Challenge4_Test_Task3_GT.txt')),\n",
        "               ts_lbl=dict(URL='https://download.openmmlab.com/mmocr/data/mixture/icdar_2015/test_label.txt',\n",
        "                           fpath=os.path.join(root,'test_label.txt')),\n",
        "               tr_lbl=dict(URL='https://download.openmmlab.com/mmocr/data/mixture/icdar_2015/train_label.txt',\n",
        "                           fpath=os.path.join(root,'train_label.txt')),\n",
        "               )\n",
        "\n",
        "\n",
        "    for dp in ([root,dts,dtr]):\n",
        "        ch_make_folder(dp)\n",
        "\n",
        "\n",
        "    for dp in (['tr_img','ts_img','ts_lbl','tr_lbl']):\n",
        "        check_dw(dpath[dp]['fpath'],dpath[dp]['URL'])\n",
        "\n",
        "\n",
        "\n",
        "    logging.info(f'Unpacking file')\n",
        "    for dp, dirc_f in zip(['tr_img','ts_img'],\n",
        "                          [dtr,dts]):\n",
        "        logging.info(f\"Unpacking {dpath[dp]['fpath']} to {dirc_f}. \")\n",
        "        shutil.unpack_archive(dpath[dp]['fpath'],dirc_f)\n",
        "\n",
        "\n",
        "    if cleanup:\n",
        "        logging.info ('Cleaning up')\n",
        "        for dp in ['tr_img','ts_img']:\n",
        "            os.remove(dpath[dp]['fpath'])\n",
        "\n",
        "    #  ```\n",
        "    #   text\n",
        "    # ├── icdar2015\n",
        "    # │   ├── imgs\n",
        "    # │   ├── annotations\n",
        "    # │   ├── instances_test.json\n",
        "    # │   └── instances_training.json\n",
        "    # ```\n",
        "icdar2015('/content/drive/MyDrive/dataset/recognition')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIQvcnJBWWps"
      },
      "source": [
        "## [Text Detection](https://mmocr.readthedocs.io/en/latest/datasets/det.html#icdar-2015)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIljBOp6WZ1P"
      },
      "outputs": [],
      "source": [
        "def icdar2015(npath,cleanup=False):\n",
        "\n",
        "    \"\"\"\n",
        "    # Detection\n",
        "    Got to many `ignore text` when extracting the annotation\n",
        "    \"\"\"\n",
        "    root=os.path.join(npath,'icdar2015')\n",
        "    dannot=os.path.join(root,'annotations')\n",
        "    dcrops=os.path.join(root,'imgs')\n",
        "\n",
        "    dpath=dict(tr_img=dict(URL = \"https://rrc.cvc.uab.es/downloads/ch4_training_images.zip\",\n",
        "                           fpath=os.path.join(root,'ch4_training_images.zip')),\n",
        "               tr_lbl=dict(URL='https://rrc.cvc.uab.es/downloads/ch4_training_localization_transcription_gt.zip',\n",
        "                           fpath=os.path.join(root,'ch4_test_images.zip')),\n",
        "               ts_img=dict(URL='https://rrc.cvc.uab.es/downloads/ch4_test_images.zip',\n",
        "                           fpath=os.path.join(root,'ch4_training_localization_transcription_gt.zip')),\n",
        "               ts_lbl=dict(URL='https://rrc.cvc.uab.es/downloads/Challenge4_Test_Task1_GT.zip',\n",
        "                           fpath=os.path.join(root,'Challenge4_Test_Task1_GT.zip'))\n",
        "               )\n",
        "\n",
        "\n",
        "    ch_make_folder(root)\n",
        "\n",
        "    for dp in (['tr_img','ts_img','ts_lbl','tr_lbl']):\n",
        "        check_dw(dpath[dp]['fpath'],dpath[dp]['URL'])\n",
        "\n",
        "\n",
        "\n",
        "    dimg_tr=os.path.join(dcrops,'training')\n",
        "    dimg_ts=os.path.join(dcrops,'test')\n",
        "    lbl_tr=os.path.join(dannot,'training')\n",
        "    lbl_ts=os.path.join(dannot,'test')\n",
        "\n",
        "    logging.info(f'Unpacking file')\n",
        "    for dp, dirc_f in zip(['tr_img','ts_img','tr_lbl','ts_lbl'],\n",
        "                          [dimg_tr,dimg_ts,lbl_tr,lbl_ts]):\n",
        "        logging.info(f\"Unpacking {dpath[dp]['fpath']} to {dirc_f}. \")\n",
        "        shutil.unpack_archive(dpath[dp]['fpath'],dirc_f)\n",
        "\n",
        "\n",
        "\n",
        "    # generate instances_training.json and instances_test.json with the following command:\n",
        "\n",
        "    # python tools/data/textdet/icdar_converter.py /path/to/icdar2015 -o /path/to/icdar2015 -d icdar2015 --split-list training test\n",
        "\n",
        "    \"\"\"\n",
        "    Why got to may ignore text?\n",
        "    \"\"\"\n",
        "\n",
        "    import os.path as osp\n",
        "    import mmcv\n",
        "    from tools.data.textdet.icdar_converter import collect_files,collect_annotations,convert_annotations\n",
        "\n",
        "    icdar_path = root\n",
        "    out_dir= root\n",
        "    dataset='icdar2015'\n",
        "    split_list=['training', 'test']\n",
        "    nproc=10\n",
        "    out_dir = out_dir if out_dir else icdar_path\n",
        "    mmcv.mkdir_or_exist(out_dir)\n",
        "\n",
        "    img_dir = osp.join(icdar_path, 'imgs')\n",
        "    gt_dir = osp.join(icdar_path, 'annotations')\n",
        "\n",
        "    set_name = {}\n",
        "    for split in split_list:\n",
        "        set_name.update({split: 'instances_' + split + '.json'})\n",
        "        assert osp.exists(osp.join(img_dir, split))\n",
        "\n",
        "    for split, json_name in set_name.items():\n",
        "        print(f'Converting {split} into {json_name}')\n",
        "        with mmcv.Timer(print_tmpl='It takes {}s to convert icdar annotation'):\n",
        "            files = collect_files(\n",
        "                osp.join(img_dir, split), osp.join(gt_dir, split))\n",
        "            image_infos = collect_annotations(\n",
        "                files, dataset, nproc=nproc)\n",
        "            convert_annotations(image_infos, osp.join(out_dir, json_name))\n",
        "\n",
        "icdar2015('/content/drive/MyDrive/dataset/detection')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voUV5XqhQ53O"
      },
      "source": [
        "# IIIT5K"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGmHHVbfbihO"
      },
      "source": [
        "## [Text Recognition](https://mmocr.readthedocs.io/en/latest/datasets/recog.html#iiit5k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzboG71yQ39c"
      },
      "outputs": [],
      "source": [
        "def IIIT5K(npath,cleanup=False):\n",
        "    \"\"\"\n",
        "      # Recognition\n",
        "      Remark: IIIT5K does not have special python  converter\n",
        "      :param npath: \n",
        "      :param cleanup: \n",
        "      :return: \n",
        "    \"\"\"\n",
        "    root=os.path.join(npath,'IIIT5K')\n",
        "    dpath=dict(dt_img=dict(URL = \"http://cvit.iiit.ac.in/projects/SceneTextUnderstanding/IIIT5K-Word_V3.0.tar.gz\",\n",
        "                           fpath=os.path.join(root,'IIIT5K-Word_V3.0.tar.gz')),\n",
        "               ts_lbl=dict(URL='https://download.openmmlab.com/mmocr/data/mixture/IIIT5K/test_label.txt',\n",
        "                           fpath=os.path.join(root,'test_label.txt')),\n",
        "               tr_lbl=dict(URL='https://download.openmmlab.com/mmocr/data/mixture/IIIT5K/train_label.txt',\n",
        "                           fpath=os.path.join(root,'train_label.txt')),\n",
        "               )\n",
        "\n",
        "    ch_make_folder(root)\n",
        "\n",
        "    for dp in (['dt_img','ts_lbl','tr_lbl']):\n",
        "        check_dw(dpath[dp]['fpath'],dpath[dp]['URL'])\n",
        "\n",
        "    logging.info(f'Unpacking file')\n",
        "    shutil.unpack_archive(dpath['dt_img']['fpath'],root)\n",
        "\n",
        "    logging.info(f'Moving file')\n",
        "    ftest_from=os.path.join(root,'IIIT5K','test')\n",
        "    shutil.move(ftest_from,root)\n",
        "\n",
        "    ftrain_from=os.path.join(root,'IIIT5K','train')\n",
        "    shutil.move(ftrain_from,root)\n",
        "\n",
        "    if cleanup:\n",
        "        logging.info ('Cleaning up')\n",
        "        shutil.rmtree(os.path.join(root,'IIIT5K'))\n",
        "        os.remove(dpath['dt_img']['fpath'])\n",
        "\n",
        "    # ├── III5K\n",
        "    # │   ├── train_label.txt\n",
        "    # │   ├── test_label.txt\n",
        "    # │   ├── train\n",
        "    # │   └── test\n",
        "\n",
        "IIIT5K('/content/drive/MyDrive/dataset/recognition')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1B4-rwpWQNx"
      },
      "source": [
        "# SVT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2Bt59crihyJ"
      },
      "source": [
        "## [Text Recognition](https://mmocr.readthedocs.io/en/latest/datasets/recog.html#svt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEy2JWDoUy7Y",
        "outputId": "b56ebdf2-3008-461a-98fe-71bce86ed61e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Downloading svt.zip from http://www.iapr-tc11.org/dataset/SVT/svt.zip.\n",
            "INFO:root:Downloading svt.zip from http://www.iapr-tc11.org/dataset/SVT/svt.zip.\n",
            "INFO:root:Downloading test_label.txt from https://download.openmmlab.com/mmocr/data/mixture/svt/test_label.txt.\n",
            "INFO:root:Downloading test_label.txt from https://download.openmmlab.com/mmocr/data/mixture/svt/test_label.txt.\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "INFO:root:Unpacking file\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finish to generate svt testset, with label file /content/drive/MyDrive/dataset/recognition/svt/test_label.txt\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def list_to_file(filename, lines):\n",
        "    \"\"\"Write a list of strings to a text file.\n",
        "\n",
        "    Args:\n",
        "        filename (str): The output filename. It will be created/overwritten.\n",
        "        lines (list(str)): Data to be written.\n",
        "    \"\"\"\n",
        "    import mmcv\n",
        "    mmcv.mkdir_or_exist(os.path.dirname(filename))\n",
        "    with open(filename, 'w', encoding='utf-8') as fw:\n",
        "        for line in lines:\n",
        "            fw.write(f'{line}\\n')\n",
        "\n",
        "def svt(npath,cleanup=False,height=32,width=100,resize=False):\n",
        "    # Recognition\n",
        "    import os.path as osp\n",
        "    import xml.etree.ElementTree as ET\n",
        "    import cv2\n",
        "    root=os.path.join(npath,'svt')\n",
        "\n",
        "    dimg=os.path.join(root,'image')\n",
        "    dpath=dict(dt_img=dict(URL = \"http://www.iapr-tc11.org/dataset/SVT/svt.zip\",\n",
        "                           fpath=os.path.join(root,'svt.zip')),\n",
        "               ts_lbl=dict(URL='https://download.openmmlab.com/mmocr/data/mixture/svt/test_label.txt',\n",
        "                           fpath=os.path.join(root,'test_label.txt'))\n",
        "               )\n",
        "\n",
        "\n",
        "    for dp in ([root,dimg]):\n",
        "        ch_make_folder(dp)\n",
        "\n",
        "    for dp in (['dt_img','ts_lbl']):\n",
        "        check_dw(dpath[dp]['fpath'],dpath[dp]['URL'])\n",
        "\n",
        "    logging.info(f'Unpacking file')\n",
        "    shutil.unpack_archive(dpath['dt_img']['fpath'],root)\n",
        "    # inputs\n",
        "    root_path=os.path.join(root,'svt1')\n",
        "    src_label_file = osp.join(root_path, 'test.xml')\n",
        "    if not osp.exists(src_label_file):\n",
        "        raise Exception(\n",
        "            f'{src_label_file} not exists, please check and try again.')\n",
        "    src_image_root = root_path\n",
        "\n",
        "    # outputs\n",
        "    dst_label_file = osp.join(root, 'test_label.txt')\n",
        "    dst_image_root = dimg\n",
        "\n",
        "    tree = ET.parse(src_label_file)\n",
        "    rootxmls = tree.getroot()\n",
        "\n",
        "    index = 1\n",
        "    lines = []\n",
        "    total_img_num = len(rootxmls)\n",
        "    i = 1\n",
        "    for image_node in rootxmls.findall('image'):\n",
        "        image_name = image_node.find('imageName').text\n",
        "        # print(f'[{i}/{total_img_num}] Process image: {image_name}')\n",
        "        i += 1\n",
        "        lexicon = image_node.find('lex').text.lower()\n",
        "        lexicon_list = lexicon.split(',')\n",
        "        lex_size = len(lexicon_list)\n",
        "        src_img = cv2.imread(osp.join(src_image_root, image_name))\n",
        "        for rectangle in image_node.find('taggedRectangles'):\n",
        "            x = int(rectangle.get('x'))\n",
        "            y = int(rectangle.get('y'))\n",
        "            w = int(rectangle.get('width'))\n",
        "            h = int(rectangle.get('height'))\n",
        "            rb, re = max(0, y), max(0, y + h)\n",
        "            cb, ce = max(0, x), max(0, x + w)\n",
        "            dst_img = src_img[rb:re, cb:ce]\n",
        "            text_label = rectangle.find('tag').text.lower()\n",
        "            if resize:\n",
        "                dst_img = cv2.resize(dst_img, (width, height))\n",
        "            dst_img_name = f'img_{index:04}' + '.jpg'\n",
        "            index += 1\n",
        "            dst_img_path = osp.join(dst_image_root, dst_img_name)\n",
        "            cv2.imwrite(dst_img_path, dst_img)\n",
        "            lines.append(f'{osp.basename(dst_image_root)}/{dst_img_name} '\n",
        "                         f'{text_label} {lex_size} {lexicon}')\n",
        "\n",
        "\n",
        "    list_to_file(dst_label_file, lines)\n",
        "    print(f'Finish to generate svt testset, '\n",
        "          f'with label file {dst_label_file}')\n",
        "\n",
        "    if cleanup:\n",
        "        logging.info ('Cleaning up')\n",
        "        shutil.rmtree(os.path.join(root,'__MACOSX'))\n",
        "        shutil.rmtree(os.path.join(root,'svt1'))\n",
        "        os.remove(dpath['dt_img']['fpath'])\n",
        "    #   ├── svt\n",
        "    # │   ├── test_label.txt\n",
        "    # │   └── image\n",
        "svt('/content/drive/MyDrive/dataset/recognition')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_d-nrEXWahs"
      },
      "source": [
        "# COCO-Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G19ki2Rui8lw"
      },
      "source": [
        "ICDAR2017 Robust Reading Challenge on COCO-Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95on4NtNU7Cm"
      },
      "outputs": [],
      "source": [
        "!wget http://msvocds.blob.core.windows.net/coco2014/train2014.zip --no-check-certificate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZQ4Is9hjDnF"
      },
      "source": [
        "## [Text Recognition](https://mmocr.readthedocs.io/en/latest/datasets/recog.html#coco-text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41Emp5cEWdIV",
        "outputId": "d1f357a2-92d4-499f-90ff-af203f03366f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Downloading COCO-Text-words-trainval.zip from https://datasets.cvc.uab.es/rrc/COCO-Text-words-trainval.zip.\n",
            "INFO:root:Downloading COCO-Text-words-trainval.zip from https://datasets.cvc.uab.es/rrc/COCO-Text-words-trainval.zip.\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "INFO:root:Downloading train_label.txt from https://download.openmmlab.com/mmocr/data/mixture/coco_text/train_label.txt.\n",
            "INFO:root:Downloading train_label.txt from https://download.openmmlab.com/mmocr/data/mixture/coco_text/train_label.txt.\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "INFO:root:Unpacking file\n"
          ]
        }
      ],
      "source": [
        "def coco_text(npath,cleanup=False):\n",
        "\n",
        "    \"\"\"\n",
        "    # Recognition\n",
        "    Remark: IIIT5K does not have special python  converter\n",
        "    \"\"\"\n",
        "\n",
        "    root=os.path.join(npath,'coco_text')\n",
        "    dannot=os.path.join(root,'annotations')\n",
        "    dcrops=os.path.join(root,'crops')\n",
        "    dpath=dict(dt_img=dict(URL = \"https://datasets.cvc.uab.es/rrc/COCO-Text-words-trainval.zip\",\n",
        "                           fpath=os.path.join(root,'COCO-Text-words-trainval.zip')),\n",
        "               tr_lbl=dict(URL='https://download.openmmlab.com/mmocr/data/mixture/coco_text/train_label.txt',\n",
        "                           fpath=os.path.join(root,'train_label.txt'))\n",
        "               )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for dp in ([root,dcrops,dannot]):\n",
        "        ch_make_folder(dp)\n",
        "\n",
        "    for dp in (['dt_img','tr_lbl']):\n",
        "        check_dw(dpath[dp]['fpath'],dpath[dp]['URL'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    dimg_tr=os.path.join(dcrops,'train')\n",
        "    dimg_ts=os.path.join(dcrops,'test')\n",
        "\n",
        "    logging.info(f'Unpacking file')\n",
        "    shutil.unpack_archive(dpath['dt_img']['fpath'],root)\n",
        "\n",
        "    if cleanup:\n",
        "        logging.info ('Cleaning up')\n",
        "        os.remove(dpath['dt_img']['fpath'])\n",
        "\n",
        "\n",
        "coco_text('/content/drive/MyDrive/dataset/recognition') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV_asd7Yjjjw"
      },
      "source": [
        "## Text Detection (KIV) [link text](https://mmocr.readthedocs.io/en/latest/datasets/det.html#icdar-2017)\n",
        "\n",
        "\n",
        "\n",
        "I am still confuse where to download the images.zip file. Is it from this [link](https://rrc.cvc.uab.es/?ch=5&com=downloads)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWUvoHg1lvkg"
      },
      "source": [
        "Or, generate instances_training.json and instances_test.json with the following command:\n",
        "\n",
        "`python tools/data/textdet/icdar_converter.py /path/to/icdar2015 -o /path/to/icdar2015 -d icdar2015 --split-list training test`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcskSXOXbiX0"
      },
      "source": [
        "# __MJSynth (Syn90k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KolHbOGfmE9P"
      },
      "source": [
        "## [Text Recognition](https://mmocr.readthedocs.io/en/latest/datasets/recog.html#mjsynth-syn90k)\n",
        "\n",
        "KIV since the file is to large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQ_eE3TkbqLA"
      },
      "outputs": [],
      "source": [
        "def Syn90k(npath,cleanup=False):\n",
        "  # Recognition (TODO)\n",
        "  root=os.path.join(npath,'Syn90k')\n",
        "  dannot=os.path.join(root,'annotations')\n",
        "  dcrops=os.path.join(root,'crops')\n",
        "  dpath=dict(dt_img=dict(URL = \"https://thor.robots.ox.ac.uk/~vgg/data/text/mjsynth.tar.gz\",\n",
        "                         fpath=os.path.join(root,'mjsynth.tar.gz')),\n",
        "             shfl_lbl=dict(URL = \"https://download.openmmlab.com/mmocr/data/mixture/Syn90k/shuffle_labels.txt\",\n",
        "                         fpath=os.path.join(root,'shuffle_labels.txt')),\n",
        "             ts_lbl=dict(URL='https://download.openmmlab.com/mmocr/data/mixture/Syn90k/label.txt',\n",
        "                         fpath=os.path.join(root,'label.txt'))\n",
        "             )\n",
        "  \n",
        "\n",
        "  if not isfile(dpath['dt_img']['fpath']):\n",
        "    raise (f\"Please download the file at {dpath['dt_img']['fpath']} and save the file in {root}\")\n",
        "\n",
        "\n",
        "  \n",
        "  for dp in ([root,dcrops,dannot]):\n",
        "    ch_make_folder(dp)\n",
        "\n",
        "\n",
        "  logging.info(f'This going to take a very long time to download. 9.98 Gb')\n",
        "  for dp in (['dt_img','ts_lbl','shfl_lbl']):\n",
        "    logging.info(f\"Downloading {os.path.split(dpath[dp]['fpath'])[-1]} from\"\n",
        "                     f\" {dpath[dp]['URL']}.\")\n",
        "    check_dw(dpath[dp]['fpath'],dpath[dp]['URL'])\n",
        "\n",
        "\n",
        "  logging.info(f'Unpacking file')\n",
        "\n",
        "  # python tools/data/utils/txt2lmdb.py -i data/mixture/Syn90k/label.txt -o data/mixture/Syn90k/label.lmdb\n",
        "#   ├── Syn90k\n",
        "# │   ├── shuffle_labels.txt\n",
        "# │   ├── label.txt\n",
        "# │   ├── label.lmdb (optional)\n",
        "# │   └── mnt\n",
        "Syn90k('/content')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zCGkEl2mdqj"
      },
      "source": [
        "# [SynthText](https://mmocr.readthedocs.io/en/latest/datasets/det.html#synthtext)\n",
        "\n",
        "Yet  to test since the file is damn large\n",
        "\n",
        "\n",
        "Overview\n",
        "\n",
        "This is a synthetically generated dataset, in which word instances are placed in natural scene images, while taking into account the scene layout.\n",
        "\n",
        "The dataset consists of 800 thousand images with approximately 8 million synthetic word instances. Each text instance is annotated with its text-string, word-level and character-level bounding-boxes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "va4hWZU96Rge"
      },
      "source": [
        "# __SynthText (Synth800k)\n",
        "KIV since the file is to large\n",
        "\n",
        "\n",
        "Overview\n",
        "\n",
        "This is a synthetically generated dataset, in which word instances are placed in natural scene images, while taking into account the scene layout.\n",
        "\n",
        "The dataset consists of 800 thousand images with approximately 8 million synthetic word instances. Each text instance is annotated with its text-string, word-level and character-level bounding-boxes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIqP0Hmtp55Z"
      },
      "source": [
        "## [Text Recognition](https://mmocr.readthedocs.io/en/latest/datasets/recog.html#synthtext-synth800k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djCXHshbf7ym"
      },
      "outputs": [],
      "source": [
        "def SynthText(npath,cleanup=False):\n",
        "  root=os.path.join(npath,'SynthText')\n",
        "  dpath=dict(dt_img=dict(URL = \"https://thor.robots.ox.ac.uk/~vgg/data/scenetext/SynthText.zip\",\n",
        "                         fpath=os.path.join(root,'SynthText.zip')),\n",
        "             lbl_txt=dict(URL='https://download.openmmlab.com/mmocr/data/mixture/SynthText/label.txt',\n",
        "                         fpath=os.path.join(root,'label.txt')),\n",
        "             lbl_shfl=dict(URL='https://download.openmmlab.com/mmocr/data/mixture/SynthText/shuffle_labels.txt',\n",
        "                         fpath=os.path.join(root,'shuffle_labels.txt')),\n",
        "             lbl_tr=dict(URL='https://download.openmmlab.com/mmocr/data/mixture/SynthText/instances_train.txt',\n",
        "                         fpath=os.path.join(root,'instances_train'))\n",
        "             )\n",
        "  \n",
        "  ch_make_folder(root)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for dp in (['lbl_shfl','lbl_txt','lbl_tr']):\n",
        "    check_dw(dpath[dp]['fpath'],dpath[dp]['URL'])\n",
        "\n",
        "\n",
        "  if not isfile(dpath['dt_img']['fpath']):\n",
        "    raise (f\"This file is large which is about 38Gb,Please download the file at {dpath['dt_img']['fpath']} and save the file in {root}\\\n",
        "    Further instruction on how to download the dataset can be found at https://www.robots.ox.ac.uk/~vgg/data/scenetext/\")\n",
        "\n",
        "\n",
        "# ├── SynthText\n",
        "# │   ├── alphanumeric_labels.txt\n",
        "# │   ├── shuffle_labels.txt\n",
        "# │   ├── instances_train.txt\n",
        "# │   ├── label.txt\n",
        "# │   ├── label.lmdb (optional)\n",
        "# │   └── synthtext\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vPW8mcOptW5"
      },
      "source": [
        "## [Text Detection](https://mmocr.readthedocs.io/en/latest/datasets/det.html#synthtext)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXeeSgobc5lV",
        "outputId": "9ae863e3-e744-4ded-a44e-5bcc5efc26ae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:This going to take a very long time to download\n",
            "INFO:root:The file /content/Syn90k/dds.txt is not availaible, downloading from https://download.openmmlab.com/mmocr/data/mixture/Syn90k/label.txt\n",
            "INFO:root:Unpacking file\n"
          ]
        }
      ],
      "source": [
        "def synthtext(npath,cleanup=False):\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  The SynthText dataset (74 GiB) is available for download via BitTorrent from Academic Torrents. \n",
        "  This includes the pre-generated dataset as well as the pre-processed background images.\n",
        "\n",
        "  We strongly recommend the use of BitTorrent protocol. For when that is not possible, \n",
        "  the pre-generated dataset (38 GiB) is available for download over http. For instructions\n",
        "   on how to download the pre-processed background images over http, see the SynthText project on github.\n",
        "\n",
        "  \"\"\"\n",
        "  root=os.path.join(npath,'Syn90k')\n",
        "  # dannot=os.path.join(root,'annotations')\n",
        "  dcrops=os.path.join(root,'imgs')\n",
        "  dpath=dict(dt_img=dict(URL = \"https://thor.robots.ox.ac.uk/~vgg/data/scenetext/SynthText.zip\",\n",
        "                         fpath=os.path.join(root,'SynthText.zip')),\n",
        "             lbl_dta=dict(URL = \"https://download.openmmlab.com/mmocr/data/synthtext/instances_training.lmdb/data.mdb\",\n",
        "                         fpath=os.path.join(root,'data.mdb')),\n",
        "             lbl_loc=dict(URL='https://download.openmmlab.com/mmocr/data/synthtext/instances_training.lmdb/lock.mdb',\n",
        "                         fpath=os.path.join(root,'lock.mdb'))\n",
        "             )\n",
        "  \n",
        "\n",
        "  # if not isfile(dpath['dt_img']['fpath']):\n",
        "  #   raise (f\"Please download the file at {dpath['dt_img']['fpath']} and save the file in {root}\")\n",
        "\n",
        "\n",
        "  \n",
        "  for dp in ([root,dcrops]):\n",
        "    ch_make_folder(dp)\n",
        "\n",
        "\n",
        "  logging.info(f'This going to take a very long time to download. 38 Gb')\n",
        "  for dp in (['dt_img','lbl_loc','lbl_dta']):\n",
        "    logging.info(f\"Downloading {os.path.split(dpath[dp]['fpath'])[-1]} from\"\n",
        "                     f\" {dpath[dp]['URL']}.\")\n",
        "    check_dw(dpath[dp]['fpath'],dpath[dp]['URL'])\n",
        "\n",
        "  logging.info(f'Unpacking file')\n",
        "  shutil.unpack_archive(dpath['dt_img']['fpath'],dcrops)\n",
        "\n",
        "\n",
        "  # ├── synthtext\n",
        "  # │   ├── imgs\n",
        "  # │   └── instances_training.lmdb\n",
        "  # │       ├── data.mdb\n",
        "  # │       └── lock.mdb\n",
        "synthtext('/content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdxbGErn8Hyt"
      },
      "outputs": [],
      "source": [
        "SynthText('/content')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNn-07bP9-X1"
      },
      "source": [
        "# __SynthAdd (KIV)\n",
        "\n",
        "KIV SINCE THE WEBSITE IS IN CHINESE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KM3Mm7-rDcd"
      },
      "source": [
        "## [Text Recognition](https://mmocr.readthedocs.io/en/latest/datasets/recog.html#synthadd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZXaEgax-BOh"
      },
      "outputs": [],
      "source": [
        "def SynthAdd(npath):\n",
        "  # TODO: REQUIRE LOGIN IN CHINESE\n",
        "  root=os.path.join(npath,'SynthAdd')\n",
        "  # dannot=os.path.join(root,'annotations')\n",
        "  # dcrops=os.path.join(root,'crops')\n",
        "  dpath=dict(dt_img=dict(URL = \"https://thor.robots.ox.ac.uk/~vgg/data/scenetext/SynthText.zip\",\n",
        "                         fpath=os.path.join(root,'SynthText.zip')),\n",
        "             lbl_txt=dict(URL='https://download.openmmlab.com/mmocr/data/mixture/SynthAdd/label.txt',\n",
        "                         fpath=os.path.join(root,'label.txt')),\n",
        "             )\n",
        "  \n",
        "  ch_make_folder(root)\n",
        "\n",
        "\n",
        "  check_dw(dpath['lbl_txt']['fpath'],dpath['lbl_txt']['URL'])\n",
        "\n",
        "  if not isfile(dpath['dt_img']['fpath']):\n",
        "    raise (f\"This file is large which is about 38Gb,Please download the file at {dpath['dt_img']['fpath']} and save the file in {root}\\\n",
        "    Further instruction on how to download the dataset can be found at https://www.robots.ox.ac.uk/~vgg/data/scenetext/\")\n",
        "\n",
        "SynthAdd('/content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mrz6L0uf-Gmo"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czDXKuc42Bss",
        "outputId": "1c2d0b46-ca0b-48e3-a3a0-e580770751a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-06-13 02:17:44--  https://dl.fbaipublicfiles.com/textvqa/images/train_val_images.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7072297970 (6.6G) [application/zip]\n",
            "Saving to: ‘train_val_images.zip’\n",
            "\n",
            "train_val_images.zi 100%[===================>]   6.59G  61.8MB/s    in 98s     \n",
            "\n",
            "2022-06-13 02:19:22 (68.9 MB/s) - ‘train_val_images.zip’ saved [7072297970/7072297970]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://dl.fbaipublicfiles.com/textvqa/images/train_val_images.zip --no-check-certificate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BIGMHeK-cGG"
      },
      "source": [
        "#TextOCR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "To3Zm93Yrhc1"
      },
      "source": [
        "## [Text Recognition](https://mmocr.readthedocs.io/en/latest/datasets/recog.html#textocr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWYSrGZBJkfL",
        "outputId": "66738660-75e6-4e9d-a908-0b0bf291decf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-06-17 01:09:22--  https://dl.fbaipublicfiles.com/textvqa/images/train_val_images.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7072297970 (6.6G) [application/zip]\n",
            "Saving to: ‘/content/drive/MyDrive/dataset/recognition/textocr/train_val_images.zip.1’\n",
            "\n",
            "train_val_images.zi 100%[===================>]   6.59G  39.6MB/s    in 3m 10s  \n",
            "\n",
            "2022-06-17 01:12:32 (35.5 MB/s) - ‘/content/drive/MyDrive/dataset/recognition/textocr/train_val_images.zip.1’ saved [7072297970/7072297970]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -P /content/drive/MyDrive/dataset/recognition/textocr https://dl.fbaipublicfiles.com/textvqa/images/train_val_images.zip --no-check-certificate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJwPZHbK-ft6"
      },
      "outputs": [],
      "source": [
        "def textocr(npath,cleanup=False):\n",
        "  # Recognition\n",
        "  root=os.path.join(npath,'textocr')\n",
        "  dpath=dict(dt_img=dict(URL = \"https://dl.fbaipublicfiles.com/textvqa/images/train_val_images.zip\",\n",
        "                         fpath=os.path.join(root,'train_val_images.zip')),\n",
        "             lbl_tr=dict(URL='https://dl.fbaipublicfiles.com/textvqa/data/textocr/TextOCR_0.1_train.json',\n",
        "                         fpath=os.path.join(root,'TextOCR_0.1_train.json')),\n",
        "             lbl_val=dict(URL='https://dl.fbaipublicfiles.com/textvqa/data/textocr/TextOCR_0.1_val.json',\n",
        "                         fpath=os.path.join(root,'TextOCR_0.1_val.json')),\n",
        "             )\n",
        "  \n",
        "  ch_make_folder(root)\n",
        "\n",
        "  # Downloading the train_val_images.zip in Google Colab might have an issue whereby the session crashed after using all available RAM. One way to bypass is to use\n",
        "  # !wget https://dl.fbaipublicfiles.com/textvqa/images/train_val_images.zip --no-check-certificate --continue \n",
        "  # and move the train_val_images.zip onto root.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for dp in (['dt_img','lbl_tr','lbl_val']):\n",
        "    check_dw(dpath[dp]['fpath'],dpath[dp]['URL'])\n",
        "\n",
        "  if not isfile(dpath['dt_img']['fpath']):\n",
        "      raise ValueError('No file available. !wget https://dl.fbaipublicfiles.com/textvqa/images/train_val_images.zip --no-check-certificate --continue ')\n",
        "\n",
        "  logging.info(f'Unpacking file and it may take sometime')\n",
        "  shutil.unpack_archive(dpath['dt_img']['fpath'],root)\n",
        "\n",
        "\n",
        "  os.rename(os.path.join(root,'train_images'),\n",
        "            os.path.join(root,'train'))\n",
        "  print('Create annotation')\n",
        "  from tools.data.textrecog.textocr_converter import convert_textocr\n",
        "  root_path=root\n",
        "  n_proc=10 # Utilise parallel processing\n",
        "  num_train_imgs = convert_textocr(\n",
        "          root_path=root_path,\n",
        "          dst_image_path='image',\n",
        "          dst_label_filename='train_label.txt',\n",
        "          annotation_filename='TextOCR_0.1_train.json',\n",
        "          nproc=n_proc)\n",
        "\n",
        "\n",
        "  print(f'Total number of the training images: {num_train_imgs}')\n",
        "  print('Processing validation set...')\n",
        "  convert_textocr(\n",
        "          root_path=root_path,\n",
        "          dst_image_path='image',\n",
        "          dst_label_filename='val_label.txt',\n",
        "          annotation_filename='TextOCR_0.1_val.json',\n",
        "          img_start_idx=num_train_imgs,\n",
        "          nproc=n_proc)\n",
        "\n",
        "  #   ├── TextOCR\n",
        "  # │   ├── image\n",
        "  # │   ├── train_label.txt\n",
        "  # │   └── val_label.txt\n",
        "textocr('/content/drive/MyDrive/dataset/recognition') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llmbop83sD-Y"
      },
      "source": [
        "## [Text Detection](https://mmocr.readthedocs.io/en/latest/datasets/det.html#textocr)\n",
        "\n",
        "File preparation for the `text detection` is similar to `text recognition` except for creating the mmocr-compatible annotation file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC8PnIRtpjpp"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBwW23e0O3o3"
      },
      "outputs": [],
      "source": [
        "!wget -P /content/drive/MyDrive/dataset/detection/textocr https://dl.fbaipublicfiles.com/textvqa/images/train_val_images.zip --no-check-certificate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iN2MjXTWS8IX"
      },
      "outputs": [],
      "source": [
        "def textocr(npath,cleanup=False):\n",
        "  # Detection\n",
        "  root=os.path.join(npath,'textocr')\n",
        "  dpath=dict(dt_img=dict(URL = \"https://dl.fbaipublicfiles.com/textvqa/images/train_val_images.zip\",\n",
        "                         fpath=os.path.join(root,'train_val_images.zip')),\n",
        "             lbl_tr=dict(URL='https://dl.fbaipublicfiles.com/textvqa/data/textocr/TextOCR_0.1_train.json',\n",
        "                         fpath=os.path.join(root,'TextOCR_0.1_train.json')),\n",
        "             lbl_val=dict(URL='https://dl.fbaipublicfiles.com/textvqa/data/textocr/TextOCR_0.1_val.json',\n",
        "                         fpath=os.path.join(root,'TextOCR_0.1_val.json')),\n",
        "             )\n",
        "\n",
        "  ch_make_folder(root)\n",
        "\n",
        "  # Downloading the train_val_images.zip in Google Colab might have an issue whereby the session crashed after using all available RAM. One way to bypass is to use\n",
        "  # !wget https://dl.fbaipublicfiles.com/textvqa/images/train_val_images.zip --no-check-certificate --continue \n",
        "  # and move the train_val_images.zip onto root.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for dp in (['dt_img','lbl_tr','lbl_val']):\n",
        "    check_dw(dpath[dp]['fpath'],dpath[dp]['URL'],wget_dw=True)\n",
        "\n",
        "  if not isfile(dpath['dt_img']['fpath']):\n",
        "      raise ValueError('No file available. !wget https://dl.fbaipublicfiles.com/textvqa/images/train_val_images.zip --no-check-certificate --continue ')\n",
        "\n",
        "  logging.info(f'Unpacking file')\n",
        "  shutil.unpack_archive(dpath['dt_img']['fpath'],root)\n",
        "\n",
        "\n",
        "  os.rename(os.path.join(root,'train_images'),\n",
        "            os.path.join(root,'train'))\n",
        "\n",
        "\n",
        "  from tools.data.textdet.textocr_converter import collect_textocr_info,convert_annotations\n",
        "  import os.path as osp\n",
        "  root_path = root\n",
        "  print('Processing training set...')\n",
        "  training_infos = collect_textocr_info(root_path, 'TextOCR_0.1_train.json')\n",
        "  convert_annotations(training_infos,\n",
        "                      osp.join(root_path, 'instances_training.json'))\n",
        "  print('Processing validation set...')\n",
        "  val_infos = collect_textocr_info(root_path, 'TextOCR_0.1_val.json')\n",
        "  convert_annotations(val_infos, osp.join(root_path, 'instances_val.json'))\n",
        "  print('Finish')\n",
        "\n",
        "\n",
        "  # The resulting directory structure looks like the following:\n",
        "\n",
        "  # ├── textocr\n",
        "  # │   ├── train\n",
        "  # │   ├── instances_training.json\n",
        "  # │   └── instances_val.json\n",
        "\n",
        "textocr('/content/drive/MyDrive/dataset/detection')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E75M1JBL_StK"
      },
      "source": [
        "# Totaltext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k092iMMskro"
      },
      "source": [
        "## [Text Recognition](https://mmocr.readthedocs.io/en/latest/datasets/recog.html#totaltext)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Asopq3-4BTos"
      },
      "outputs": [],
      "source": [
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCVexm9h_TgE",
        "outputId": "4ec27b5a-dd63-417b-c200-e91f21bf2fe8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start download\n",
            "Start download\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Unpacking file\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converting training into training_label.txt\n",
            "Loaded 1255 images from /content/drive/MyDrive/dataset/recognition/totaltext/imgs/training\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 1255/1255, 41.8 task/s, elapsed: 30s, ETA:     0s\n",
            "It takes 83.5185935497284s to convert totaltext annotation\n"
          ]
        }
      ],
      "source": [
        "def totaltext(npath,cleanup=False):\n",
        "  # Recognition\n",
        "  import gdown\n",
        "  root=os.path.join(npath,'totaltext')\n",
        "  dannot=os.path.join(root,'annotations','training')\n",
        "  dcrops=os.path.join(root,'imgs')\n",
        "\n",
        "\n",
        "  dpath=dict(dt_img=dict(URL = 'https://drive.google.com/open?id=1bC68CzsSVTusZVvOkk7imSZSbgD1MqK2&authuser=0',\n",
        "                         fpath=os.path.join(root,'totaltext.zip')),\n",
        "             lbl_tr=dict(URL='https://drive.google.com/open?id=1-XrQBoU9as1PXaB_0dUrDTJgvGFFOnDE',\n",
        "                         fpath=os.path.join(root,'TT_new_train_GT.zip')),\n",
        "             lbl_txt=dict(URL='https://drive.google.com/file/d/1v-pd-74EkZ3dWe6k0qppRtetjdPQ3ms1/view',\n",
        "                         fpath=os.path.join(root,'groundtruth_text.zip'))\n",
        "             )\n",
        "  \n",
        "\n",
        "  for dp in ([root,dannot]):\n",
        "    ch_make_folder(dp)\n",
        "\n",
        "  if not isfile(dpath['dt_img']['fpath']):\n",
        "    print('Start download')\n",
        "    gdown.download(url=dpath['dt_img']['URL'], output=dpath['dt_img']['fpath'], quiet=True, fuzzy=True)\n",
        "\n",
        "  if not isfile(dpath['lbl_tr']['fpath']):\n",
        "    print('Start download')\n",
        "    gdown.download(url=dpath['lbl_tr']['URL'], output=dpath['lbl_tr']['fpath'], quiet=True, fuzzy=True)\n",
        "\n",
        "\n",
        "\n",
        "  logging.info(f'Unpacking file')\n",
        "  shutil.unpack_archive(dpath['dt_img']['fpath'],root)\n",
        "  shutil.unpack_archive(dpath['lbl_tr']['fpath'],root)\n",
        "\n",
        "\n",
        "  os.rename(os.path.join(root,'Images','Test'),\n",
        "            os.path.join(root,'Images','test'))\n",
        "  \n",
        "  os.rename(os.path.join(root,'Images','Train'),\n",
        "            os.path.join(root,'Images','training'))\n",
        "  \n",
        "  os.rename(os.path.join(root,'Images'),\n",
        "            os.path.join(root,'imgs'))\n",
        "\n",
        "  move_files(os.path.join(root,'Train'),dannot)\n",
        "\n",
        "\n",
        "  from tools.data.textrecog.totaltext_converter import collect_files,collect_annotations,generate_ann\n",
        "  import mmcv\n",
        "  import os.path as osp\n",
        "  nproc=10\n",
        "  img_dir = osp.join(root, 'imgs')\n",
        "  gt_dir = osp.join(root, 'annotations')\n",
        "\n",
        "  set_name = {}\n",
        "  for split in ['training']:  # Originally ['training', 'test'], but since we only have `training`, we drop the `test`\n",
        "    set_name.update({split: split + '_label' + '.txt'})\n",
        "    assert osp.exists(osp.join(img_dir, split))\n",
        "\n",
        "  for split, ann_name in set_name.items():\n",
        "    print(f'Converting {split} into {ann_name}')\n",
        "    with mmcv.Timer(print_tmpl='It takes {}s to convert totaltext annotation'):\n",
        "      files = collect_files(osp.join(img_dir, split), osp.join(gt_dir, split))\n",
        "      image_infos = collect_annotations(files, nproc=nproc)\n",
        "      generate_ann(root, split, image_infos)\n",
        "\n",
        "  #   ├── TextOCR\n",
        "  # │   ├── image\n",
        "  # │   ├── train_label.txt\n",
        "  # │   └── val_label.txt\n",
        "totaltext('/content/drive/MyDrive/dataset/recognition') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiNwnCPcswLh"
      },
      "source": [
        "## [Text Detection](https://mmocr.readthedocs.io/en/latest/datasets/det.html#totaltext)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ii34OsSXn5z",
        "outputId": "3f701002-04eb-467a-d329-9579a28d138d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start download\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Unpacking file\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converting training into instances_training.json\n",
            "Loaded 1255 images from /content/drive/MyDrive/dataset/detection/totaltext/imgs/training\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 1255/1255, 41.2 task/s, elapsed: 30s, ETA:     0s\n",
            "It takes 32.14170575141907s to convert totaltext annotation\n"
          ]
        }
      ],
      "source": [
        "def totaltext(npath,cleanup=False):\n",
        "  # Detection\n",
        "  import gdown\n",
        "  root=os.path.join(npath,'totaltext')\n",
        "  dannot=os.path.join(root,'annotations','training')\n",
        "  dcrops=os.path.join(root,'imgs')\n",
        "\n",
        "\n",
        "  dpath=dict(dt_img=dict(URL = 'https://drive.google.com/open?id=1bC68CzsSVTusZVvOkk7imSZSbgD1MqK2&authuser=0',\n",
        "                         fpath=os.path.join(root,'totaltext.zip')),\n",
        "             lbl_tr=dict(URL='https://drive.google.com/open?id=1-XrQBoU9as1PXaB_0dUrDTJgvGFFOnDE',\n",
        "                         fpath=os.path.join(root,'TT_new_train_GT.zip')),\n",
        "             lbl_txt=dict(URL='https://drive.google.com/file/d/1v-pd-74EkZ3dWe6k0qppRtetjdPQ3ms1/view',\n",
        "                         fpath=os.path.join(root,'groundtruth_text.zip'))\n",
        "             )\n",
        "  \n",
        "\n",
        "  for dp in ([root,dannot]):\n",
        "    ch_make_folder(dp)\n",
        "\n",
        "  if not isfile(dpath['dt_img']['fpath']):\n",
        "    print('Start download')\n",
        "    gdown.download(url=dpath['dt_img']['URL'], output=dpath['dt_img']['fpath'], quiet=True, fuzzy=True)\n",
        "\n",
        "  if not isfile(dpath['lbl_tr']['fpath']):\n",
        "    print('Start download')\n",
        "    gdown.download(url=dpath['lbl_tr']['URL'], output=dpath['lbl_tr']['fpath'], quiet=True, fuzzy=True)\n",
        "\n",
        "\n",
        "\n",
        "  logging.info(f'Unpacking file')\n",
        "  shutil.unpack_archive(dpath['dt_img']['fpath'],root)\n",
        "  shutil.unpack_archive(dpath['lbl_tr']['fpath'],root)\n",
        "\n",
        "\n",
        "  os.rename(os.path.join(root,'Images','Test'),\n",
        "            os.path.join(root,'Images','test'))\n",
        "  \n",
        "  os.rename(os.path.join(root,'Images','Train'),\n",
        "            os.path.join(root,'Images','training'))\n",
        "  \n",
        "  os.rename(os.path.join(root,'Images'),\n",
        "            os.path.join(root,'imgs'))\n",
        "\n",
        "  move_files(os.path.join(root,'Train'),dannot)\n",
        "\n",
        "\n",
        "  from tools.data.textdet.totaltext_converter import collect_files,collect_annotations,convert_annotations\n",
        "  import mmcv\n",
        "  import os.path as osp\n",
        "  root_path = root\n",
        "  nproc=10\n",
        "  img_dir = osp.join(root_path, 'imgs')\n",
        "  gt_dir = osp.join(root_path, 'annotations')\n",
        "\n",
        "  set_name = {}\n",
        "  for split in ['training']: # Originally ['training', 'test'], but since we only have `training`, we drop the `test`\n",
        "      set_name.update({split: 'instances_' + split + '.json'})\n",
        "      assert osp.exists(osp.join(img_dir, split))\n",
        "\n",
        "  for split, json_name in set_name.items():\n",
        "      print(f'Converting {split} into {json_name}')\n",
        "      with mmcv.Timer(\n",
        "              print_tmpl='It takes {}s to convert totaltext annotation'):\n",
        "          files = collect_files(\n",
        "              osp.join(img_dir, split), osp.join(gt_dir, split))\n",
        "          image_infos = collect_annotations(files, nproc=nproc)\n",
        "          convert_annotations(image_infos, osp.join(root_path, json_name))\n",
        "\n",
        "totaltext('/content/drive/MyDrive/dataset/detection')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXGhZu69-GYj"
      },
      "source": [
        "# DeText"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5tRY7yptQ3G"
      },
      "source": [
        "## [Text Recognition](https://mmocr.readthedocs.io/en/latest/datasets/recog.html#detext)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1j3iDEcEMYL"
      },
      "outputs": [],
      "source": [
        "def detext(npath,cleanup=False):\n",
        "\n",
        "  # Recognition\n",
        "  root=os.path.join(npath,'detext')\n",
        "  dannot_tr=os.path.join(root,'annotations','training')\n",
        "  dannot_val=os.path.join(root,'annotations','val')\n",
        "  dtrain=os.path.join(root,'imgs','training')\n",
        "  dval=os.path.join(root,'imgs','val')\n",
        "\n",
        "\n",
        "  \n",
        "  dpath=dict(dt_tr=dict(URL = 'https://rrc.cvc.uab.es/downloads/ch9_training_images.zip',\n",
        "                         fpath=os.path.join(root,'ch9_training_images.zip')),\n",
        "             dt_tr_loc=dict(URL='https://rrc.cvc.uab.es/downloads/ch9_training_localization_transcription_gt.zip',\n",
        "                         fpath=os.path.join(root,'ch9_training_localization_transcription_gt.zip')),\n",
        "             dt_val=dict(URL='https://rrc.cvc.uab.es/downloads/ch9_validation_images.zip',\n",
        "                         fpath=os.path.join(root,'ch9_validation_images.zip')),\n",
        "             dt_val_loc=dict(URL='https://rrc.cvc.uab.es/downloads/ch9_validation_localization_transcription_gt.zip',\n",
        "                         fpath=os.path.join(root,'ch9_validation_localization_transcription_gt.zip')),\n",
        "             )\n",
        "  \n",
        "\n",
        "  for dp in ([root,dtrain,dval,dannot_tr,dannot_val]):\n",
        "    ch_make_folder(dp)\n",
        "\n",
        "  for dp in (['dt_tr','dt_tr_loc','dt_val','dt_val_loc']):\n",
        "    check_dw(dpath[dp]['fpath'],dpath[dp]['URL'])\n",
        "\n",
        "\n",
        "\n",
        "  logging.info(f'Unpacking file')\n",
        "  shutil.unpack_archive(dpath['dt_tr']['fpath'],dtrain)\n",
        "  shutil.unpack_archive(dpath['dt_tr_loc']['fpath'],dannot_tr)\n",
        "  shutil.unpack_archive(dpath['dt_val']['fpath'],dval)\n",
        "  shutil.unpack_archive(dpath['dt_val_loc']['fpath'],dannot_val)\n",
        "\n",
        "  from tools.data.textrecog.detext_converter import collect_files,collect_annotations,generate_ann\n",
        "\n",
        "  import os.path as osp\n",
        "\n",
        "  # root_path=root\n",
        "  nproc=10\n",
        "  preserve_vertical=True\n",
        "  format='jsonl'\n",
        "  for split in ['training', 'val']:\n",
        "    print(f'Processing {split} set...')\n",
        "    files = collect_files(\n",
        "            osp.join(root, 'imgs', split),\n",
        "            osp.join(root, 'annotations', split))\n",
        "    image_infos = collect_annotations(files, nproc=nproc)\n",
        "    generate_ann(root, split, image_infos, preserve_vertical,format)\n",
        "\n",
        "\n",
        "  # ├── detext\n",
        "  # │   ├── crops\n",
        "  # │   ├── ignores\n",
        "  # │   ├── train_label.jsonl\n",
        "  # │   └── test_label.jsonl\n",
        "detext('/content/drive/MyDrive/dataset/recognition')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2mPC3tZtX57"
      },
      "source": [
        "## [Text Detection](https://mmocr.readthedocs.io/en/latest/datasets/det.html#detext)\n",
        "\n",
        "Data preparation is similar to text recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65mUsymeV7vj"
      },
      "outputs": [],
      "source": [
        "def detext(npath,cleanup=False):\n",
        "\n",
        "  # Detection\n",
        "  root=os.path.join(npath,'detext')\n",
        "  dannot_tr=os.path.join(root,'annotations','training')\n",
        "  dannot_val=os.path.join(root,'annotations','val')\n",
        "  dtrain=os.path.join(root,'imgs','training')\n",
        "  dval=os.path.join(root,'imgs','val')\n",
        "\n",
        "\n",
        "  \n",
        "  dpath=dict(dt_tr=dict(URL = 'https://rrc.cvc.uab.es/downloads/ch9_training_images.zip',\n",
        "                         fpath=os.path.join(root,'ch9_training_images.zip')),\n",
        "             dt_tr_loc=dict(URL='https://rrc.cvc.uab.es/downloads/ch9_training_localization_transcription_gt.zip',\n",
        "                         fpath=os.path.join(root,'ch9_training_localization_transcription_gt.zip')),\n",
        "             dt_val=dict(URL='https://rrc.cvc.uab.es/downloads/ch9_validation_images.zip',\n",
        "                         fpath=os.path.join(root,'ch9_validation_images.zip')),\n",
        "             dt_val_loc=dict(URL='https://rrc.cvc.uab.es/downloads/ch9_validation_localization_transcription_gt.zip',\n",
        "                         fpath=os.path.join(root,'ch9_validation_localization_transcription_gt.zip')),\n",
        "             )\n",
        "  \n",
        "\n",
        "  for dp in ([root,dtrain,dval,dannot_tr,dannot_val]):\n",
        "    ch_make_folder(dp)\n",
        "\n",
        "  for dp in (['dt_tr','dt_tr_loc','dt_val','dt_val_loc']):\n",
        "    check_dw(dpath[dp]['fpath'],dpath[dp]['URL'])\n",
        "\n",
        "\n",
        "\n",
        "  logging.info(f'Unpacking file')\n",
        "  shutil.unpack_archive(dpath['dt_tr']['fpath'],dtrain)\n",
        "  shutil.unpack_archive(dpath['dt_tr_loc']['fpath'],dannot_tr)\n",
        "  shutil.unpack_archive(dpath['dt_val']['fpath'],dval)\n",
        "  shutil.unpack_archive(dpath['dt_val_loc']['fpath'],dannot_val)\n",
        "\n",
        "  # Step2: Generate instances_training.json and instances_val.json with following command:\n",
        "\n",
        "  from tools.data.textdet.detext_converter import collect_files,collect_annotations,convert_annotations\n",
        "  import mmcv\n",
        "  import os.path as osp\n",
        "  root_path =root\n",
        "  nproc=10\n",
        "  for split in ['training', 'val']:\n",
        "      print(f'Processing {split} set...')\n",
        "      with mmcv.Timer(\n",
        "              print_tmpl='It takes {}s to convert DeText annotation'):\n",
        "          files = collect_files(\n",
        "              osp.join(root_path, 'imgs', split),\n",
        "              osp.join(root_path, 'annotations', split))\n",
        "          image_infos = collect_annotations(files, nproc=nproc)\n",
        "          convert_annotations(\n",
        "              image_infos, osp.join(root_path,\n",
        "                                    'instances_' + split + '.json'))\n",
        "\n",
        "  # After running the above codes, the directory structure should be as follows:\n",
        "\n",
        "  # │── detext\n",
        "  # │   ├── annotations\n",
        "  # │   ├── imgs\n",
        "  # │   ├── instances_test.json\n",
        "  # │   └── instances_training.json\n",
        "\n",
        "detext('/content/drive/MyDrive/dataset/detection/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrNFuNnIJIIL"
      },
      "source": [
        "# NAF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpn_0xeCtq4r"
      },
      "source": [
        "## [Text Recognition](https://mmocr.readthedocs.io/en/latest/datasets/recog.html#naf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-gysOEQqdTo"
      },
      "outputs": [],
      "source": [
        "!pip install GitPython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_M3vE32JGND"
      },
      "outputs": [],
      "source": [
        "def naf(npath,cleanup=False):\n",
        "  # Recognition\n",
        "  from git import Repo\n",
        "  # !pip install GitPython\n",
        "  root=os.path.join(npath,'naf')\n",
        "  dannot=os.path.join(root,'annotations')\n",
        "  dpath=dict(dt_tr=dict(URL = 'https://github.com/herobd/NAF_dataset/releases/download/v1.0/labeled_images.tar.gz',\n",
        "                         fpath=os.path.join(root,'labeled_images.tar.gz')))\n",
        "  \n",
        "\n",
        "  for dp in ([root,dannot]):\n",
        "    ch_make_folder(dp)\n",
        "\n",
        "\n",
        "  logging.info ('This may take sometime to download ~800 Mb tar file')\n",
        "  check_dw(dpath['dt_tr']['fpath'],dpath['dt_tr']['URL'])\n",
        "\n",
        "  if not isfile(os.path.join(root,'NAF_dataset','train_valid_test_split.json')):\n",
        "    logging.info ('Downloading annotation from github')\n",
        "    Repo.clone_from('https://github.com/herobd/NAF_dataset.git', os.path.join(root,'NAF_dataset'))\n",
        "  \n",
        "  logging.info(f'Unpacking file')\n",
        "  shutil.unpack_archive(dpath['dt_tr']['fpath'],root)\n",
        "  os.rename(os.path.join(root,'labeled_images'), os.path.join(root,'imgs'))\n",
        "\n",
        "  logging.info ('Reorganise file and folder')\n",
        "  shutil.move(os.path.join(root,'NAF_dataset','train_valid_test_split.json'),\n",
        "              os.path.join(root,'annotations','train_valid_test_split.json'))\n",
        "\n",
        "\n",
        "  shutil.move(os.path.join(root,'NAF_dataset','groups'),\n",
        "              os.path.join(root,'annotations','groups'))\n",
        "\n",
        "\n",
        "\n",
        "  from tools.data.textrecog.naf_converter import collect_files,collect_annotations,generate_ann\n",
        "\n",
        "  import os.path as osp\n",
        "  import mmcv\n",
        "  preserve_vertical=True\n",
        "  format='jsonl'\n",
        "  nproc=4\n",
        "  root_path = root\n",
        "  split_info = mmcv.load( osp.join(root_path, 'annotations', 'train_valid_test_split.json'))\n",
        "  split_info['training'] = split_info.pop('train')\n",
        "  split_info['val'] = split_info.pop('valid')\n",
        "  for split in ['training', 'val', 'test']:\n",
        "    print(f'Processing {split} set...')\n",
        "    with mmcv.Timer(print_tmpl='It takes {}s to convert NAF annotation'):\n",
        "      files = collect_files(osp.join(root_path, 'imgs'),\n",
        "                            osp.join(root_path, 'annotations'), split_info[split])\n",
        "      image_infos = collect_annotations(files, nproc=nproc)\n",
        "      generate_ann(root_path, split, image_infos, preserve_vertical,format)\n",
        "\n",
        "\n",
        "  if cleanup:\n",
        "    logging.info ('Cleaning up')\n",
        "    shutil.rmtree(os.path.join(root,'NAF_dataset')) \n",
        "    os.remove(dpath['dt_tr']['fpath'])\n",
        "\n",
        "\n",
        "  #   ├── naf\n",
        "  # │   ├── crops\n",
        "  # │   ├── train_label.txt\n",
        "  # │   ├── val_label.txt\n",
        "  # │   └── test_label.txt\n",
        "\n",
        "  \n",
        "naf('/content/drive/MyDrive/dataset/recognition',cleanup=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJavVohst9mJ"
      },
      "source": [
        "## [Text Detection](https://mmocr.readthedocs.io/en/latest/datasets/det.html#naf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lTkxuqnZnF7"
      },
      "outputs": [],
      "source": [
        "def naf(npath,cleanup=False):\n",
        "  # Detection\n",
        "  from git import Repo\n",
        "  # !pip install GitPython\n",
        "  root=os.path.join(npath,'naf')\n",
        "  dannot=os.path.join(root,'annotations')\n",
        "  dpath=dict(dt_tr=dict(URL = 'https://github.com/herobd/NAF_dataset/releases/download/v1.0/labeled_images.tar.gz',\n",
        "                         fpath=os.path.join(root,'labeled_images.tar.gz')))\n",
        "  \n",
        "\n",
        "  for dp in ([root,dannot]):\n",
        "    ch_make_folder(dp)\n",
        "\n",
        "\n",
        "  logging.info ('This may take sometime to download ~800 Mb tar file')\n",
        "  check_dw(dpath['dt_tr']['fpath'],dpath['dt_tr']['URL'])\n",
        "\n",
        "  if not isfile(os.path.join(root,'NAF_dataset','train_valid_test_split.json')):\n",
        "    logging.info ('Downloading annotation from github')\n",
        "    Repo.clone_from('https://github.com/herobd/NAF_dataset.git', os.path.join(root,'NAF_dataset'))\n",
        "  \n",
        "  logging.info(f'Unpacking file')\n",
        "  shutil.unpack_archive(dpath['dt_tr']['fpath'],root)\n",
        "  os.rename(os.path.join(root,'labeled_images'), os.path.join(root,'imgs'))\n",
        "\n",
        "  logging.info ('Reorganise file and folder')\n",
        "  shutil.move(os.path.join(root,'NAF_dataset','train_valid_test_split.json'),\n",
        "              os.path.join(root,'annotations','train_valid_test_split.json'))\n",
        "\n",
        "\n",
        "  shutil.move(os.path.join(root,'NAF_dataset','groups'),\n",
        "              os.path.join(root,'annotations','groups'))\n",
        "\n",
        "\n",
        "\n",
        "  # Step2: Generate instances_training.json, instances_val.json, and instances_test.json with following command:\n",
        "\n",
        "  # python tools/data/textdet/naf_converter.py PATH/TO/naf --nproc 4\n",
        "\n",
        "  # After running the above codes, the directory structure should be as follows:\n",
        "\n",
        "  from tools.data.textdet.naf_converter import collect_files,collect_annotations,convert_annotations\n",
        "\n",
        "  import os.path as osp\n",
        "  import mmcv\n",
        "  nproc=10\n",
        "  root_path = root\n",
        "  split_info = mmcv.load(\n",
        "      osp.join(root_path, 'annotations', 'train_valid_test_split.json'))\n",
        "  split_info['training'] = split_info.pop('train')\n",
        "  split_info['val'] = split_info.pop('valid')\n",
        "  for split in ['training', 'val', 'test']:\n",
        "      print(f'Processing {split} set...')\n",
        "      with mmcv.Timer(print_tmpl='It takes {}s to convert NAF annotation'):\n",
        "          files = collect_files(\n",
        "              osp.join(root_path, 'imgs'),\n",
        "              osp.join(root_path, 'annotations'), split_info[split])\n",
        "          image_infos = collect_annotations(files, nproc=nproc)\n",
        "          convert_annotations(\n",
        "              image_infos, osp.join(root_path,\n",
        "                                    'instances_' + split + '.json'))\n",
        "        \n",
        "\n",
        "  # │── naf\n",
        "  # │   ├── annotations\n",
        "  # │   ├── imgs\n",
        "  # │   ├── instances_test.json\n",
        "  # │   ├── instances_val.json\n",
        "  # │   └── instances_training.json\n",
        "\n",
        "  \n",
        "naf('/content/drive/MyDrive/dataset/detection',cleanup=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tin6DP4f3zU1"
      },
      "source": [
        "# Lecture Video DB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOkdlw_luWkn"
      },
      "source": [
        "## [Text Recognition](https://mmocr.readthedocs.io/en/latest/datasets/recog.html#lecture-video-db)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QViWmm6q3T7-",
        "outputId": "42814867-16a0-404a-efdb-919bd4f5cfa1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:This may take sometime to download ~2.26 Gb zip file (~2 m)\n",
            "INFO:root:Downloading IIIT-CVid.zip from http://cdn.iiit.ac.in/cdn/preon.iiit.ac.in/~kartik/IIIT-CVid.zip.\n",
            "INFO:root:Unpacking file\n",
            "INFO:root:Reorganise file and folder\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train split converted.\n",
            "val split converted.\n",
            "test split converted.\n"
          ]
        }
      ],
      "source": [
        "def lv(npath,cleanup=False):\n",
        "\n",
        "  # Recognition\n",
        "  \n",
        "  from git import Repo\n",
        "  # !pip install GitPython\n",
        "  root=os.path.join(npath,'lv')\n",
        "  dannot=os.path.join(root,'annotations')\n",
        "  dpath=dict(dt_tr=dict(URL = 'http://cdn.iiit.ac.in/cdn/preon.iiit.ac.in/~kartik/IIIT-CVid.zip',\n",
        "                         fpath=os.path.join(root,'IIIT-CVid.zip')))\n",
        "  \n",
        "  ch_make_folder(root)\n",
        "\n",
        "  \n",
        "\n",
        "  logging.info ('This may take sometime to download ~2.26 Gb zip file (~2 m)')\n",
        "  check_dw(dpath['dt_tr']['fpath'],dpath['dt_tr']['URL'])\n",
        "\n",
        "  \n",
        "  logging.info(f'Unpacking file')\n",
        "  shutil.unpack_archive(dpath['dt_tr']['fpath'],root)\n",
        "\n",
        "  logging.info ('Reorganise file and folder')\n",
        "  shutil.move(os.path.join(root,'IIIT-CVid','Crops'),\n",
        "              os.path.join(root,'Crops'))\n",
        "\n",
        "  shutil.move(os.path.join(root,'IIIT-CVid','train.txt'),\n",
        "              os.path.join(root,'train_label.txt'))\n",
        "\n",
        "  shutil.move(os.path.join(root,'IIIT-CVid','val.txt'),\n",
        "              os.path.join(root,'val_label.txt'))\n",
        "  \n",
        "  shutil.move(os.path.join(root,'IIIT-CVid','test.txt'),\n",
        "              os.path.join(root,'test_label.txt'))\n",
        "\n",
        "\n",
        "  from tools.data.textrecog.lv_converter import convert_annotations\n",
        "\n",
        "  root_path=root\n",
        "  format='jsonl'\n",
        "  for split in ['train', 'val', 'test']:\n",
        "    convert_annotations(root_path, split, format)\n",
        "    print(f'{split} split converted.')\n",
        "\n",
        "  # TODO. move the test_label,train_label_val_label from iiit-cvid to root\n",
        "  if cleanup:\n",
        "    logging.info ('Cleaning up')\n",
        "    shutil.rmtree(os.path.join(root,'NAF_dataset')) \n",
        "    os.remove(dpath['dt_tr']['fpath'])\n",
        "\n",
        "\n",
        "# ├── lv\n",
        "# │   ├── Crops\n",
        "# │   ├── train_label.jsonl\n",
        "# │   └── test_label.jsonl\n",
        "\n",
        "  \n",
        "lv('/content/drive/MyDrive/dataset/recognition') # Done verification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAHXh960uiSg"
      },
      "source": [
        "## [Text Detection](https://mmocr.readthedocs.io/en/latest/datasets/det.html#lecture-video-db)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This example require user to modify\n",
        "\n",
        "the line\n",
        "\n",
        " `img_file = img_file.split('data/lv/')[1]`\n",
        "\n",
        " to \n",
        "\n",
        "`img_file =os.path.split(img_file)[-1]`\n",
        "\n",
        "at\n",
        "\n",
        "`mmocr/tools/data/textdet/lv_converter.py`\n",
        "\n",
        "The issue has been raised at [Issue 1078](https://github.com/open-mmlab/mmocr/issues/1078) for  `File out of list!`\n",
        "\n"
      ],
      "metadata": {
        "id": "64X1b9GW_SHB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N09pHCd0bMxG",
        "outputId": "24dc839a-47fa-4535-ad61-b5e504e39b94"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:This may take sometime to download ~2.26 Gb zip file (download time about ~5 mins with Colab)\n",
            "INFO:root:Unpacking file\n",
            "INFO:root:Reorganise file and folder\n"
          ]
        }
      ],
      "source": [
        "def lv(npath,cleanup=False):\n",
        "  # Detection\n",
        "  # Only working with tools.data.textdet.lv_converter\n",
        "  from git import Repo\n",
        "  # !pip install GitPython\n",
        "  root=os.path.join(npath,'lv')\n",
        "  dannot=os.path.join(root,'annotations')\n",
        "  dpath=dict(dt_tr=dict(URL = 'http://cdn.iiit.ac.in/cdn/preon.iiit.ac.in/~kartik/IIIT-CVid.zip',\n",
        "                         fpath=os.path.join(root,'IIIT-CVid.zip')))\n",
        "  \n",
        "  ch_make_folder(root)\n",
        "\n",
        "  \n",
        "\n",
        "  logging.info ('This may take sometime to download ~2.26 Gb zip file (download time about ~5 mins with Colab)')\n",
        "  check_dw(dpath['dt_tr']['fpath'],dpath['dt_tr']['URL'],wget_dw=True)\n",
        "\n",
        "  \n",
        "  logging.info(f'Unpacking file')\n",
        "  shutil.unpack_archive(dpath['dt_tr']['fpath'],root)\n",
        "\n",
        "  logging.info ('Reorganise file and folder')\n",
        "  shutil.move(os.path.join(root,'IIIT-CVid','Frames'),  # Diffrence frame vs crop\n",
        "              os.path.join(root,'imgs'))\n",
        "\n",
        "  # Step2: Generate instances_training.json, instances_val.json, and instances_test.json with following command:\n",
        "\n",
        "  # python tools/data/textdet/lv_converter.py PATH/TO/lv --nproc 4\n",
        "\n",
        "\n",
        "  from tools.data.textdet.lv_converter import collect_files,collect_annotations,convert_annotations\n",
        "  import os.path as osp\n",
        "  import mmcv\n",
        "  nproc=4\n",
        "  root_path = '/content/detection/lv'\n",
        "\n",
        "  for split in ['train', 'val', 'test']:\n",
        "      print(f'Processing {split} set...')\n",
        "      with mmcv.Timer(print_tmpl='It takes {}s to convert LV annotation'):\n",
        "          files = collect_files(osp.join(root_path, 'imgs', split))\n",
        "          print(files)\n",
        "          image_infos = collect_annotations(files, nproc=nproc)\n",
        "          convert_annotations(\n",
        "              image_infos, osp.join(root_path,\n",
        "                                    'instances_' + split + '.json'))\n",
        "\n",
        "  # The resulting directory structure looks like the following:\n",
        "\n",
        "\n",
        "  if cleanup:\n",
        "    logging.info ('Cleaning up')\n",
        "    shutil.rmtree(os.path.join(root,'NAF_dataset')) \n",
        "    os.remove(dpath['dt_tr']['fpath'])\n",
        "\n",
        "\n",
        "  # │── lv\n",
        "  # │   ├── imgs\n",
        "  # │   ├── instances_test.json\n",
        "  # │   ├── instances_training.json\n",
        "  # │   └── instances_val.json\n",
        "\n",
        "  \n",
        "lv('/content/detection/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQnNfCscfzM0"
      },
      "outputs": [],
      "source": [
        "from tools.data.textdet.lv_converter import collect_files,collect_annotations,convert_annotations\n",
        "import os.path as osp\n",
        "import mmcv\n",
        "nproc=4\n",
        "root_path = '/content/detection/lv'\n",
        "\n",
        "for split in ['train', 'val', 'test']:\n",
        "    print(f'Processing {split} set...')\n",
        "    with mmcv.Timer(print_tmpl='It takes {}s to convert LV annotation'):\n",
        "        files = collect_files(osp.join(root_path, 'imgs', split))\n",
        "        print(files)\n",
        "        image_infos = collect_annotations(files, nproc=nproc)\n",
        "        convert_annotations(\n",
        "            image_infos, osp.join(root_path,\n",
        "                                  'instances_' + split + '.json'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjvp-Clh-Zhl"
      },
      "source": [
        "#  LSVT\n",
        "\n",
        "Han Character"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaXN_J6RvHyb"
      },
      "source": [
        "## [Text Recognition](https://mmocr.readthedocs.io/en/latest/datasets/recog.html#lsvt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iEd-Cjd9o9b"
      },
      "outputs": [],
      "source": [
        "def lsvt(npath,cleanup=False):\n",
        "\n",
        "\n",
        "  # Recognition\n",
        "  root=os.path.join(npath,'lsvt')\n",
        "  dannot=os.path.join(root,'annotations')\n",
        "  dimg=os.path.join(root,'imgs')\n",
        "  dpath=dict(dt_img1=dict(URL = 'https://dataset-bj.cdn.bcebos.com/lsvt/train_full_images_0.tar.gz',\n",
        "                         fpath=os.path.join(root,'train_full_images_0.tar.gz')),\n",
        "             dt_img2=dict(URL = 'https://dataset-bj.cdn.bcebos.com/lsvt/train_full_images_1.tar.gz',\n",
        "                         fpath=os.path.join(root,'train_full_images_1.tar.gz')),\n",
        "             lbl=dict(URL = 'http://dataset-bj.cdn.bcebos.com/lsvt/train_full_labels.json',\n",
        "                         fpath=os.path.join(root,'train_full_labels.json')),\n",
        "            )\n",
        "  \n",
        "  \n",
        "  for dp in ([root,dimg,dannot]):\n",
        "    ch_make_folder(dp)\n",
        "\n",
        "  logging.info ('This may take sometime to download ~8 Gb zip file (20 m)')\n",
        "  for dp in ['dt_img1','dt_img2','lbl']:\n",
        "    check_dw(dpath[dp]['fpath'],dpath[dp]['URL'])\n",
        "\n",
        "  \n",
        "  logging.info(f'Unpacking file')\n",
        "  shutil.unpack_archive(dpath['dt_img1']['fpath'],root)\n",
        "  os.rename(os.path.join(root,'train_full_images_0'), os.path.join(root,'imgs'))\n",
        "\n",
        "  shutil.unpack_archive(dpath['dt_img2']['fpath'],root)\n",
        "  source_dir=os.path.join(root,'train_full_images_1')\n",
        "\n",
        "  move_files(source_dir,dimg)\n",
        "\n",
        "  logging.info ('Reorganise file and folder')\n",
        "  shutil.move(os.path.join(root,'train_full_labels.json'),dannot)\n",
        "\n",
        "\n",
        "  from tools.data.textrecog.lsvt_converter import convert_lsvt\n",
        "  root_path = root\n",
        "\n",
        "  preserve_vertical=True\n",
        "  val_ratio=0.2\n",
        "  nproc=10\n",
        "  print('Processing training set...')\n",
        "  num_train_imgs = convert_lsvt(\n",
        "      root_path=root_path,\n",
        "      split='train',\n",
        "      ratio=val_ratio,\n",
        "      preserve_vertical=preserve_vertical,\n",
        "      format=format,\n",
        "      nproc=nproc)\n",
        "  \n",
        "\n",
        "  if val_ratio > 0:\n",
        "      print('Processing validation set...')\n",
        "      convert_lsvt(\n",
        "          root_path=root_path,\n",
        "          split='val',\n",
        "          ratio=val_ratio,\n",
        "          preserve_vertical=preserve_vertical,\n",
        "          format=format,\n",
        "          nproc=nproc,\n",
        "          img_start_idx=num_train_imgs)\n",
        "  print('Finish')\n",
        "\n",
        "  if cleanup:\n",
        "    logging.info ('Cleaning up')\n",
        "    shutil.rmtree(os.path.join(root,'train_full_images_1')) \n",
        "    os.remove(dpath['dt_img1']['fpath'])\n",
        "    os.remove(dpath['dt_img2']['fpath'])\n",
        "\n",
        "\n",
        "  # ├── lsvt\n",
        "  # │   ├── crops\n",
        "  # │   ├── ignores\n",
        "  # │   ├── train_label.jsonl\n",
        "  # │   └── val_label.jsonl (optional)\n",
        "\n",
        "  \n",
        "lsvt('/content/drive/MyDrive/dataset/recognition') # Got problem, to debug in local"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sEtRymAvRkm"
      },
      "source": [
        "## [Text Detection](https://mmocr.readthedocs.io/en/latest/datasets/det.html#lsvt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU3RMHHoi4qB",
        "outputId": "8a82b215-f83c-413b-eb80-20d4de767b78"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:This may take sometime to download ~8 Gb zip file (20 m)\n",
            "INFO:root:Downloading train_full_images_0.tar.gz from https://dataset-bj.cdn.bcebos.com/lsvt/train_full_images_0.tar.gz.\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "INFO:root:Downloading train_full_images_1.tar.gz from https://dataset-bj.cdn.bcebos.com/lsvt/train_full_images_1.tar.gz.\n",
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n"
          ]
        }
      ],
      "source": [
        "def lsvt(npath,cleanup=False):\n",
        "\n",
        "  #Detection\n",
        "\n",
        "  root=os.path.join(npath,'lsvt')\n",
        "  dannot=os.path.join(root,'annotations')\n",
        "  dimg=os.path.join(root,'imgs')\n",
        "  dpath=dict(dt_img1=dict(URL = 'https://dataset-bj.cdn.bcebos.com/lsvt/train_full_images_0.tar.gz',\n",
        "                         fpath=os.path.join(root,'train_full_images_0.tar.gz')),\n",
        "             dt_img2=dict(URL = 'https://dataset-bj.cdn.bcebos.com/lsvt/train_full_images_1.tar.gz',\n",
        "                         fpath=os.path.join(root,'train_full_images_1.tar.gz')),\n",
        "             lbl=dict(URL = 'http://dataset-bj.cdn.bcebos.com/lsvt/train_full_labels.json',\n",
        "                         fpath=os.path.join(root,'train_full_labels.json')),\n",
        "            )\n",
        "  \n",
        "  \n",
        "  for dp in ([root,dimg,dannot]):\n",
        "    ch_make_folder(dp)\n",
        "\n",
        "  logging.info ('This may take sometime to download ~8 Gb zip file (20 m)')\n",
        "  for dp in ['dt_img1','dt_img2','lbl']:\n",
        "    check_dw(dpath[dp]['fpath'],dpath[dp]['URL'])\n",
        "\n",
        "  \n",
        "  logging.info(f'Unpacking file')\n",
        "  shutil.unpack_archive(dpath['dt_img1']['fpath'],root)\n",
        "  os.rename(os.path.join(root,'train_full_images_0'), os.path.join(root,'imgs'))\n",
        "\n",
        "  shutil.unpack_archive(dpath['dt_img2']['fpath'],root)\n",
        "  source_dir=os.path.join(root,'train_full_images_1')\n",
        "\n",
        "  move_files(source_dir,dimg)\n",
        "\n",
        "  logging.info ('Reorganise file and folder')\n",
        "  shutil.move(os.path.join(root,'train_full_labels.json'),dannot)\n",
        "\n",
        "\n",
        "\n",
        "  from tools.data.textdet.lsvt_converter import collect_lsvt_info,convert_annotations\n",
        "  import os.path as osp\n",
        "  val_ratio=0.2\n",
        "  root_path = root\n",
        "  print('Processing training set...')\n",
        "  training_infos = collect_lsvt_info(root_path, 'train', val_ratio)\n",
        "  convert_annotations(training_infos,\n",
        "                      osp.join(root_path, 'instances_training.json'))\n",
        "  if val_ratio > 0:\n",
        "      print('Processing validation set...')\n",
        "      val_infos = collect_lsvt_info(root_path, 'val', val_ratio)\n",
        "      convert_annotations(val_infos, osp.join(root_path,\n",
        "                                              'instances_val.json'))\n",
        "  print('Finish')\n",
        "\n",
        "\n",
        "  # # Annotations of LSVT test split is not publicly available, split a validation\n",
        "  # # set by adding --val-ratio 0.2\n",
        "  # python tools/data/textdet/lsvt_converter.py PATH/TO/lsvt\n",
        "\n",
        "  # After running the above codes, the directory structure should be as follows:\n",
        "\n",
        "  # |── lsvt\n",
        "  # │   ├── imgs\n",
        "  # │   ├── instances_training.json\n",
        "  # │   └── instances_val.json (optional)\n",
        "\n",
        "  if cleanup:\n",
        "    logging.info ('Cleaning up')\n",
        "    shutil.rmtree(os.path.join(root,'train_full_images_1')) \n",
        "    os.remove(dpath['dt_img1']['fpath'])\n",
        "    os.remove(dpath['dt_img2']['fpath'])\n",
        "\n",
        "\n",
        "  \n",
        "lsvt('/content/drive/MyDrive/dataset/detection') # Works like a charm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jVcv8-wGrnq"
      },
      "source": [
        "# FUNSD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV43N8yzvzR-"
      },
      "source": [
        "## [Text Recognition](https://mmocr.readthedocs.io/en/latest/datasets/recog.html#funsd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjoAFeM_Gtf-"
      },
      "outputs": [],
      "source": [
        "def funsd(npath,cleanup=False):\n",
        "\n",
        "\n",
        "  #Recognition\n",
        "  root=os.path.join(npath,'funsd')\n",
        "  dannot_ts=os.path.join(root,'annotations','test')\n",
        "  dannot_tr=os.path.join(root,'annotations','training')\n",
        "  dimg=os.path.join(root,'imgs')\n",
        "  dpath=dict(dt_img=dict(URL = 'https://guillaumejaume.github.io/FUNSD/dataset.zip',\n",
        "                         fpath=os.path.join(root,'dataset.zip'))\n",
        "            )\n",
        "  \n",
        "\n",
        "  for dp in ([root,dannot_ts,dimg,dannot_tr]):\n",
        "    ch_make_folder(dp)\n",
        "\n",
        "  logging.info ('This may take sometime to download ~8 Gb zip file')\n",
        "  check_dw(dpath['dt_img']['fpath'],dpath['dt_img']['URL'])\n",
        "\n",
        "  \n",
        "  logging.info(f'Unpacking file')\n",
        "  shutil.unpack_archive(dpath['dt_img']['fpath'],root)\n",
        "\n",
        "\n",
        "\n",
        "  move_files(os.path.join(root,'dataset','training_data','images'),\n",
        "             dimg)\n",
        "\n",
        "\n",
        "  move_files(os.path.join(root,'dataset','testing_data','images'),\n",
        "            dimg) # img_ts \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  move_files(os.path.join(root,'dataset','testing_data','annotations'),\n",
        "             dannot_ts)\n",
        "\n",
        "\n",
        "\n",
        "  move_files(os.path.join(root,'dataset','training_data','annotations'),\n",
        "             dannot_tr)\n",
        "  \n",
        "\n",
        "\n",
        "  if cleanup:\n",
        "    logging.info ('Cleaning up')\n",
        "    shutil.rmtree(os.path.join(root,'__MACOSX')) \n",
        "    shutil.rmtree(os.path.join(root,'dataset')) \n",
        "    os.remove(dpath['dt_img']['fpath'])\n",
        "\n",
        "  from tools.data.textrecog.funsd_converter import collect_files,collect_annotations,generate_ann\n",
        "  import os.path as osp\n",
        "  import mmcv\n",
        "  nproc=10\n",
        "  preserve_vertical=True\n",
        "  format='jsonl'\n",
        "  root_path = root\n",
        "\n",
        "  for split in ['training', 'test']:\n",
        "      print(f'Processing {split} set...')\n",
        "      with mmcv.Timer(print_tmpl='It takes {}s to convert FUNSD annotation'):\n",
        "          files = collect_files(\n",
        "              osp.join(root_path, 'imgs'),\n",
        "              osp.join(root_path, 'annotations', split))\n",
        "          image_infos = collect_annotations(files, nproc=nproc)\n",
        "          generate_ann(root_path, split, image_infos, preserve_vertical,\n",
        "                      format)\n",
        "\n",
        "\n",
        "  # ├── funsd\n",
        "  # │   ├── imgs\n",
        "  # │   ├── dst_imgs\n",
        "  # │   ├── annotations\n",
        "  # │   ├── train_label.txt\n",
        "  # │   └── test_label.txt\n",
        "\n",
        "  \n",
        "funsd('/content/drive/MyDrive/dataset/recognition') # Check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDKz-nORv99K"
      },
      "source": [
        "## [Text Detection](https://mmocr.readthedocs.io/en/latest/datasets/det.html#funsd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnHkpPCrN5dc"
      },
      "outputs": [],
      "source": [
        "def funsd(npath,cleanup=False):\n",
        "\n",
        "  # Detection\n",
        "\n",
        "  root=os.path.join(npath,'funsd')\n",
        "  dannot_ts=os.path.join(root,'annotations','test')\n",
        "  dannot_tr=os.path.join(root,'annotations','training')\n",
        "  dimg=os.path.join(root,'imgs')\n",
        "  dpath=dict(dt_img=dict(URL = 'https://guillaumejaume.github.io/FUNSD/dataset.zip',\n",
        "                         fpath=os.path.join(root,'dataset.zip'))\n",
        "            )\n",
        "  \n",
        "\n",
        "  for dp in ([root,dannot_ts,dimg,dannot_tr]):\n",
        "    ch_make_folder(dp)\n",
        "\n",
        "  logging.info ('This may take sometime to download ~8 Gb zip file')\n",
        "  check_dw(dpath['dt_img']['fpath'],dpath['dt_img']['URL'],wget_dw=True)\n",
        "\n",
        "  \n",
        "  logging.info(f'Unpacking file')\n",
        "  shutil.unpack_archive(dpath['dt_img']['fpath'],root)\n",
        "\n",
        "\n",
        "\n",
        "  move_files(os.path.join(root,'dataset','training_data','images'),\n",
        "             dimg)\n",
        "\n",
        "\n",
        "  move_files(os.path.join(root,'dataset','testing_data','images'),\n",
        "            dimg) # img_ts \n",
        "\n",
        "\n",
        "  move_files(os.path.join(root,'dataset','testing_data','annotations'),\n",
        "             dannot_ts)\n",
        "\n",
        "\n",
        "  move_files(os.path.join(root,'dataset','training_data','annotations'),\n",
        "             dannot_tr)\n",
        "  \n",
        "  from tools.data.textdet.funsd_converter import collect_files,collect_annotations,convert_annotations\n",
        "  import os.path as osp\n",
        "  import mmcv\n",
        "  nproc=10\n",
        "  root_path = root\n",
        "\n",
        "  for split in ['training', 'test']:\n",
        "      print(f'Processing {split} set...')\n",
        "      with mmcv.Timer(print_tmpl='It takes {}s to convert FUNSD annotation'):\n",
        "          files = collect_files(\n",
        "              osp.join(root_path, 'imgs'),\n",
        "              osp.join(root_path, 'annotations', split))\n",
        "          image_infos = collect_annotations(files, nproc=nproc)\n",
        "          convert_annotations(\n",
        "              image_infos, osp.join(root_path,\n",
        "                                    'instances_' + split + '.json'))\n",
        "  # The resulting directory structure looks like the following:\n",
        "\n",
        "  # │── funsd\n",
        "  # │   ├── annotations\n",
        "  # │   ├── imgs\n",
        "  # │   ├── instances_test.json\n",
        "  # │   └── instances_training.json\n",
        "\n",
        "\n",
        "  if cleanup:\n",
        "    logging.info ('Cleaning up')\n",
        "    shutil.rmtree(os.path.join(root,'__MACOSX')) \n",
        "    shutil.rmtree(os.path.join(root,'dataset')) \n",
        "    os.remove(dpath['dt_img']['fpath'])\n",
        "\n",
        "\n",
        "  \n",
        "funsd('/content/drive/MyDrive/dataset/detection') # Work like a charm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQncXZGGO5FP"
      },
      "source": [
        "# COCO Text v2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDEQgp3JwRCW"
      },
      "source": [
        "## [Text Recognition](https://mmocr.readthedocs.io/en/latest/datasets/recog.html#coco-text-v2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrs5MG-I4epB",
        "outputId": "103294d1-d792-4a6b-9d54-21fda743f7e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsdE7-AAO-sq",
        "outputId": "4ba29cd5-2a28-4488-83df-c1e202e16332"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:This may take sometime to download ~12.58 Gb zip file\n",
            "INFO:root:Downloading train2014.zip from http://images.cocodataset.org/zips/train2014.zip.\n"
          ]
        }
      ],
      "source": [
        "def coco_textv2(npath,cleanup=False):\n",
        "\n",
        "\n",
        "  # Recognition\n",
        "  root=os.path.join(npath,'coco_textv2')\n",
        "  dannot=os.path.join(root,'annotations')\n",
        "\n",
        "  # dimg=os.path.join(root,'imgs')\n",
        "\n",
        "  dpath=dict(dt_tr=dict(URL = 'http://images.cocodataset.org/zips/train2014.zip',\n",
        "                         fpath=os.path.join(root,'train2014.zip')),\n",
        "             dt_trx=dict(URL = 'https://github.com/bgshih/cocotext/releases/download/dl/cocotext.v2.zip',\n",
        "                         fpath=os.path.join(root,'cocotext.v2.zip'))\n",
        "            )\n",
        "  \n",
        "\n",
        "  for dp in ([root,dannot]):\n",
        "    ch_make_folder(dp)\n",
        "\n",
        "  # Potential error with Google Colab wherby the session crashed after using all available RAM\n",
        "  logging.info ('This may take sometime to download ~12.58 Gb zip file')\n",
        "\n",
        "  for dp in ['dt_tr','dt_trx']:\n",
        "    check_dw(dpath[dp]['fpath'],dpath[dp]['URL'],wget_dw=False)\n",
        "\n",
        "  logging.info(f'Unpacking file')\n",
        "  shutil.unpack_archive(dpath['dt_tr']['fpath'],root)\n",
        "  shutil.unpack_archive(dpath['dt_trx']['fpath'],root)\n",
        "\n",
        "  os.rename(os.path.join(root,'train2014'),\n",
        "            os.path.join(root,'imgs'))\n",
        "\n",
        "  shutil.move(os.path.join(root, 'cocotext.v2.json'),\n",
        "              dannot)\n",
        "\n",
        "\n",
        "  from tools.data.textrecog.cocotext_converter import convert_cocotext\n",
        "  root_path = root\n",
        "  preserve_vertical=True\n",
        "  nproc=10\n",
        "  format='jsonl'\n",
        "  print('Processing training set...')\n",
        "  num_train_imgs = convert_cocotext(\n",
        "      root_path=root_path,\n",
        "      split='train',\n",
        "      preserve_vertical=preserve_vertical,\n",
        "      format=format,\n",
        "      nproc=nproc)\n",
        "  print('Processing validation set...')\n",
        "  convert_cocotext(\n",
        "      root_path=root_path,\n",
        "      split='val',\n",
        "      preserve_vertical=preserve_vertical,\n",
        "      format=format,\n",
        "      nproc=nproc,\n",
        "      img_start_idx=num_train_imgs)\n",
        "  print('Finish')\n",
        "\n",
        "  if cleanup:\n",
        "    logging.info ('Cleaning up')\n",
        "    shutil.rmtree(os.path.join(root,'dataset')) \n",
        "    os.remove(dpath['dt_tr']['fpath'])\n",
        "    os.remove(dpath['dt_trx']['fpath'])\n",
        "\n",
        "  #   ├── coco_textv2\n",
        "  # │   ├── crops\n",
        "  # │   ├── ignores\n",
        "  # │   ├── train_label.jsonl\n",
        "  # │   └── val_label.jsonl\n",
        "    \n",
        "coco_textv2('/content/drive/MyDrive/dataset/recognition') # Working locally"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8xpWK6Lwd2-"
      },
      "source": [
        "## [Text Detection](https://mmocr.readthedocs.io/en/latest/datasets/det.html#coco-text-v2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VwEFCDejqOB",
        "outputId": "1d3021f8-0dc9-4b0f-ce53-8e24e937b5df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:This may take sometime to download ~12.58 Gb zip file\n",
            "INFO:root:Downloading train2014.zip from http://images.cocodataset.org/zips/train2014.zip.\n",
            "INFO:root:Downloading cocotext.v2.zip from https://github.com/bgshih/cocotext/releases/download/dl/cocotext.v2.zip.\n",
            "INFO:root:Unpacking file\n"
          ]
        }
      ],
      "source": [
        "def coco_textv2(npath,cleanup=False):\n",
        "\n",
        "\n",
        "\n",
        "  root=os.path.join(npath,'coco_textv2')\n",
        "  dannot=os.path.join(root,'annotations')\n",
        "\n",
        "  # dimg=os.path.join(root,'imgs')\n",
        "\n",
        "  dpath=dict(dt_tr=dict(URL = 'http://images.cocodataset.org/zips/train2014.zip',\n",
        "                         fpath=os.path.join(root,'train2014.zip')),\n",
        "             dt_trx=dict(URL = 'https://github.com/bgshih/cocotext/releases/download/dl/cocotext.v2.zip',\n",
        "                         fpath=os.path.join(root,'cocotext.v2.zip'))\n",
        "            )\n",
        "  \n",
        "\n",
        "  for dp in ([root,dannot]):\n",
        "    ch_make_folder(dp)\n",
        "\n",
        "  # Potential error with Google Colab wherby the session crashed after using all available RAM\n",
        "  logging.info ('This may take sometime to download ~12.58 Gb zip file')\n",
        "\n",
        "  for dp in ['dt_tr','dt_trx']:\n",
        "    check_dw(dpath[dp]['fpath'],dpath[dp]['URL'],wget_dw=True)\n",
        "\n",
        "  logging.info(f'Unpacking file')\n",
        "  shutil.unpack_archive(dpath['dt_tr']['fpath'],root)\n",
        "  shutil.unpack_archive(dpath['dt_trx']['fpath'],root)\n",
        "\n",
        "  os.rename(os.path.join(root,'train2014'),\n",
        "            os.path.join(root,'imgs'))\n",
        "\n",
        "  shutil.move(os.path.join(root, 'cocotext.v2.json'),\n",
        "              dannot)\n",
        "\n",
        "\n",
        "\n",
        "  from tools.data.textdet.cocotext_converter import collect_cocotext_info,convert_annotations\n",
        "  import os.path as osp\n",
        "\n",
        "  # preserve_vertical=True\n",
        "  # nproc=10\n",
        "  # format='jsonl'\n",
        "\n",
        "\n",
        "  root_path =root\n",
        "  print('Processing training set...')\n",
        "  training_infos = collect_cocotext_info(root_path, 'train')\n",
        "  convert_annotations(training_infos,\n",
        "                      osp.join(root_path, 'instances_training.json'))\n",
        "  print('Processing validation set...')\n",
        "  val_infos = collect_cocotext_info(root_path, 'val')\n",
        "  convert_annotations(val_infos, osp.join(root_path, 'instances_val.json'))\n",
        "  print('Finish')\n",
        "\n",
        "\n",
        "  if cleanup:\n",
        "    logging.info ('Cleaning up')\n",
        "    shutil.rmtree(os.path.join(root,'dataset')) \n",
        "    os.remove(dpath['dt_tr']['fpath'])\n",
        "    os.remove(dpath['dt_trx']['fpath'])\n",
        "\n",
        "  # Step2: Generate instances_training.json and instances_val.json with the following command:\n",
        "\n",
        "  # python tools/data/textdet/cocotext_converter.py PATH/TO/coco_textv2\n",
        "\n",
        "  # After running the above codes, the directory structure should be as follows:\n",
        "\n",
        "  # │── coco_textv2\n",
        "  # │   ├── annotations\n",
        "  # │   ├── imgs\n",
        "  # │   ├── instances_training.json\n",
        "  # │   └── instances_val.json\n",
        "    \n",
        "coco_textv2('/content/drive/MyDrive/dataset/detection') # Work like a charm at local"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0_PTFvCTPcW"
      },
      "source": [
        "# Vintext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPsCXwP2w-3i"
      },
      "source": [
        "## [Text Recognition](https://mmocr.readthedocs.io/en/latest/datasets/recog.html#vintext)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4amqqEoXhkM"
      },
      "outputs": [],
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1UUQhNvzgpZy7zXBFQp0Qox-BBjunZ0ml' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1UUQhNvzgpZy7zXBFQp0Qox-BBjunZ0ml\" -O vintext.zip && rm -rf /tmp/cookies.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5613fs7IbXG2"
      },
      "outputs": [],
      "source": [
        "def vintext(npath,cleanup=False):\n",
        "\n",
        "  # Recognition\n",
        "\n",
        "  root=os.path.join(npath,'vintext')\n",
        "  dannot=os.path.join(root,'annotations')\n",
        "\n",
        "  dimg=os.path.join(root,'imgs')\n",
        "  dimg_tr=os.path.join(dimg,'training')\n",
        "  dimg_ts=os.path.join(dimg,'test')\n",
        "  dimg_ur=os.path.join(dimg,'unseen_test')\n",
        "  dpath=dict(dt_img=dict(URL = 'https://docs.google.com/uc?export=download&id=1UUQhNvzgpZy7zXBFQp0Qox-BBjunZ0ml',\n",
        "                         fpath=os.path.join(root,'vintext.zip'))\n",
        "            )\n",
        "  \n",
        "  for dp in [root,dannot,dimg,\n",
        "             dimg_tr,\n",
        "             dimg_ur,\n",
        "             dimg_ts]:\n",
        "    ch_make_folder(dp)\n",
        "\n",
        "\n",
        "  if not isfile(dpath['dt_img']['fpath']):\n",
        "      fd,fname=os.path.split(dpath['dt_img']['fpath'])\n",
        "      logging.info (f'Please download the {fname} and stored under {fd}.or use the command')\n",
        "      # raise ('wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1UUQhNvzgpZy7zXBFQp0Qox-BBjunZ0ml' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1UUQhNvzgpZy7zXBFQp0Qox-BBjunZ0ml\" -O vintext.zip && rm -rf /tmp/cookies.txt')\n",
        "\n",
        "\n",
        "  logging.info(f'Unpacking file')\n",
        "  shutil.unpack_archive(dpath['dt_img']['fpath'],root)\n",
        "\n",
        "\n",
        "  logging.info(f'Create annotation')\n",
        "  for dfrom,dto in zip(['labels','train_images','test_image','unseen_test_images'],\n",
        "                       [dannot,dimg_tr,dimg_ts,dimg_ur]):\n",
        "    move_files(os.path.join(root,'vietnamese',dfrom),dto)\n",
        "\n",
        " \n",
        "\n",
        "  preserve_vertical=True\n",
        "  nproc=10\n",
        "  format='jsonl'\n",
        "  import os.path as osp\n",
        "  import mmcv\n",
        "  from tools.data.textrecog.vintext_converter import collect_files,collect_annotations,generate_ann\n",
        "  root_path = root\n",
        "  for split in ['training', 'test', 'unseen_test']:\n",
        "      print(f'Processing {split} set...')\n",
        "      with mmcv.Timer(\n",
        "              print_tmpl='It takes {}s to convert VinText annotation'):\n",
        "          files = collect_files(\n",
        "              osp.join(root_path, 'imgs', split),\n",
        "              osp.join(root_path, 'annotations'))\n",
        "          image_infos = collect_annotations(files, nproc=nproc)\n",
        "          generate_ann(root_path, split, image_infos, preserve_vertical,\n",
        "                      format)\n",
        "        \n",
        "  if cleanup:\n",
        "    logging.info ('Cleaning up')\n",
        "    shutil.rmtree(os.path.join(root,'vietnamese')) \n",
        "    os.remove(dpath['dt_img']['fpath'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "vintext('/content/drive/MyDrive/dataset/recognition') # Working locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTLECPUKeItV"
      },
      "outputs": [],
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1UUQhNvzgpZy7zXBFQp0Qox-BBjunZ0ml' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1UUQhNvzgpZy7zXBFQp0Qox-BBjunZ0ml\" -O vintext.zip && rm -rf /tmp/cookies.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S_0FtuJimcD"
      },
      "source": [
        "##[Text Detection](https://mmocr.readthedocs.io/en/latest/datasets/det.html#vintext)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AH903E9QiMg"
      },
      "outputs": [],
      "source": [
        "\n",
        "def vintext(npath,cleanup=False):\n",
        "\n",
        "    # Detection\n",
        "\n",
        "    root=os.path.join(npath,'vintext')\n",
        "    dannot=os.path.join(root,'annotations')\n",
        "\n",
        "    dimg=os.path.join(root,'imgs')\n",
        "    dimg_tr=os.path.join(dimg,'training')\n",
        "    dimg_ts=os.path.join(dimg,'test')\n",
        "    dimg_ur=os.path.join(dimg,'unseen_test')\n",
        "    dpath=dict(dt_img=dict(URL = 'https://docs.google.com/uc?export=download&id=1UUQhNvzgpZy7zXBFQp0Qox-BBjunZ0ml',\n",
        "                           fpath=os.path.join(root,'vietnamese_original.zip'))\n",
        "               )\n",
        "\n",
        "    for dp in [root,dannot,dimg,\n",
        "               dimg_tr,\n",
        "               dimg_ur,\n",
        "               dimg_ts]:\n",
        "        ch_make_folder(dp)\n",
        "\n",
        "\n",
        "    if not isfile(dpath['dt_img']['fpath']):\n",
        "        fd,fname=os.path.split(dpath['dt_img']['fpath'])\n",
        "        logging.info (f'Please download the {fname} and stored under {fd}.or use the command')\n",
        "        # raise ('wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1UUQhNvzgpZy7zXBFQp0Qox-BBjunZ0ml' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1UUQhNvzgpZy7zXBFQp0Qox-BBjunZ0ml\" -O vintext.zip && rm -rf /tmp/cookies.txt')\n",
        "\n",
        "\n",
        "    logging.info(f'Unpacking file')\n",
        "    shutil.unpack_archive(dpath['dt_img']['fpath'],root)\n",
        "\n",
        "\n",
        "    logging.info('Move files')\n",
        "    for dfrom,dto in zip(['labels','train_images','test_image','unseen_test_images'],\n",
        "                         [dannot,dimg_tr,dimg_ts,dimg_ur]):\n",
        "        move_files(os.path.join(root,'vietnamese',dfrom),dto)\n",
        "\n",
        "    nproc=10\n",
        "\n",
        "    from tools.data.textdet.vintext_converter import collect_files,collect_annotations,convert_annotations\n",
        "    root_path = root\n",
        "    print('Prepare annotation')\n",
        "    for split in ['training', 'test', 'unseen_test']:\n",
        "        print(f'Processing {split} set...')\n",
        "        with mmcv.Timer(\n",
        "                print_tmpl='It takes {}s to convert VinText annotation'):\n",
        "            files = collect_files(\n",
        "                osp.join(root_path, 'imgs', split),\n",
        "                osp.join(root_path, 'annotations'))\n",
        "            image_infos = collect_annotations(files, nproc=nproc)\n",
        "            convert_annotations(\n",
        "                image_infos, osp.join(root_path,\n",
        "                                      'instances_' + split + '.json'))\n",
        "\n",
        "    if cleanup:\n",
        "        logging.info ('Cleaning up')\n",
        "        shutil.rmtree(os.path.join(root,'vietnamese'))\n",
        "        os.remove(dpath['dt_img']['fpath'])\n",
        "  # Step2: Generate instances_training.json, instances_test.json and instances_unseen_test.json\n",
        "\n",
        "  # python tools/data/textdet/vintext_converter.py PATH/TO/vintext --nproc 4\n",
        "\n",
        "  # After running the above codes, the directory structure should be as follows:\n",
        "\n",
        "  # │── vintext\n",
        "  # │   ├── annotations\n",
        "  # │   ├── imgs\n",
        "  # │   ├── instances_test.json\n",
        "  # │   ├── instances_unseen_test.json\n",
        "  # │   └── instances_training.json\n",
        "\n",
        "  vintext('/content/drive/MyDrive/dataset/detection') # Work like a charm at local\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CIw6W0UTjdM"
      },
      "source": [
        "# BID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8lNFu3TxSxB"
      },
      "source": [
        "## [Text Recognition](https://mmocr.readthedocs.io/en/latest/datasets/recog.html#bid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rR2GIN-hi0Sb"
      },
      "outputs": [],
      "source": [
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJqTXZieiJDZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "def bid(npath,cleanup=False):\n",
        "    # Recognition\n",
        "    import gdown\n",
        "\n",
        "    from glob import glob\n",
        "\n",
        "    root=os.path.join(npath,'bid')\n",
        "\n",
        "\n",
        "    dannot=os.path.join(root,'annotations')\n",
        "\n",
        "    dimg=os.path.join(root,'imgs')\n",
        "\n",
        "    dpath=dict(dt_img=dict(URL = 'https://drive.google.com/uc?id=1Oi88TRcpdjZmJ79WDLb9qFlBNG8q2De6&export=download',\n",
        "                           fpath=os.path.join(root,'BID Dataset.zip'))\n",
        "               )\n",
        "\n",
        "\n",
        "    for dp in ([root,dannot,dimg]):\n",
        "        ch_make_folder(dp)\n",
        "\n",
        "\n",
        "    if not isfile(dpath['dt_img']['fpath']):\n",
        "        logging.info ('It may take sometime to download 6.81 Gb zip file from Google Drive')\n",
        "        # url = 'https://drive.google.com/uc?id=1Oi88TRcpdjZmJ79WDLb9qFlBNG8q2De6&export=download'\n",
        "        gdown.download(dpath['dt_img']['URL'], dpath['dt_img']['fpath'], quiet=False)\n",
        "\n",
        "    logging.info ('It may take sometime to extract 6.81 Gb zip')\n",
        "    shutil.unpack_archive(dpath['dt_img']['fpath'],root)\n",
        "\n",
        "    ls_jpg=glob(os.path.join(root,'BID Dataset','*','*.jpg'))\n",
        "    ls_txt=glob(os.path.join(root,'BID Dataset','*','*.txt'))\n",
        "\n",
        "    for ls_ext,ls_dest in zip([ls_jpg,ls_txt],\n",
        "                      [dimg,dannot]):\n",
        "        move_files_to_des(ls_ext,ls_dest)\n",
        "\n",
        "\n",
        "    root_path = root\n",
        "    preserve_vertical=True\n",
        "    nproc=10\n",
        "    format='jsonl'\n",
        "    val_ratio=0.2\n",
        "    import os.path as osp\n",
        "    import mmcv\n",
        "    from tools.data.textrecog.bid_converter import collect_files,collect_annotations,generate_ann\n",
        "    # root_path = '/content/bid'\n",
        "    with mmcv.Timer(print_tmpl='It takes {}s to convert BID annotation'):\n",
        "        files = collect_files(\n",
        "            osp.join(root_path, 'imgs'), osp.join(root_path, 'annotations'))\n",
        "        print('Start Collect annotation')\n",
        "        image_infos = collect_annotations(files, nproc=nproc)\n",
        "        print('Start Generating  annotation')\n",
        "        generate_ann(root_path, image_infos, preserve_vertical,\n",
        "                     val_ratio, format)\n",
        "        \n",
        "                \n",
        "\n",
        "\n",
        "        \n",
        "    if cleanup:\n",
        "        logging.info ('Cleaning up')\n",
        "        move_files(os.path.join(root,'vietnamese','labels'),dannot)\n",
        "  \n",
        "#     ├── BID\n",
        "# │   ├── crops\n",
        "# │   ├── ignores\n",
        "# │   ├── train_label.jsonl\n",
        "# │   └── val_label.jsonl (optional)\n",
        "bid('/content/drive/MyDrive/dataset/recognition') # Work like a charm locally"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-52LNmG-xbQO"
      },
      "source": [
        "## [Text Detection](https://mmocr.readthedocs.io/en/latest/datasets/det.html#bid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMFRdpWAkFQQ",
        "outputId": "8cf62988-b22a-437d-9a46-4dc724580cd4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:It may take sometime to extract 6.81 Gb zip\n"
          ]
        }
      ],
      "source": [
        "def bid(npath,cleanup=False):\n",
        "\n",
        "    import gdown\n",
        "\n",
        "    from glob import glob\n",
        "\n",
        "    root=os.path.join(npath,'bid')\n",
        "\n",
        "\n",
        "    dannot=os.path.join(root,'annotations')\n",
        "\n",
        "    dimg=os.path.join(root,'imgs')\n",
        "\n",
        "    dpath=dict(dt_img=dict(URL = 'https://drive.google.com/uc?id=1Oi88TRcpdjZmJ79WDLb9qFlBNG8q2De6&export=download',\n",
        "                           fpath=os.path.join(root,'BID Dataset.zip'))\n",
        "               )\n",
        "\n",
        "\n",
        "    for dp in ([root,dannot,dimg]):\n",
        "        ch_make_folder(dp)\n",
        "\n",
        "\n",
        "    if not isfile(dpath['dt_img']['fpath']):\n",
        "        logging.info ('It may take sometime to download 6.81 Gb zip file from Google Drive')\n",
        "        # url = 'https://drive.google.com/uc?id=1Oi88TRcpdjZmJ79WDLb9qFlBNG8q2De6&export=download'\n",
        "        gdown.download(dpath['dt_img']['URL'], dpath['dt_img']['fpath'], quiet=False)\n",
        "\n",
        "    logging.info ('It may take sometime to extract 6.81 Gb zip')\n",
        "    shutil.unpack_archive(dpath['dt_img']['fpath'],root)\n",
        "\n",
        "    ls_jpg=glob(os.path.join(root,'BID Dataset','*','*.jpg'))\n",
        "    ls_txt=glob(os.path.join(root,'BID Dataset','*','*.txt'))\n",
        "\n",
        "    for ls_ext,ls_dest in zip([ls_jpg,ls_txt],\n",
        "                      [dimg,dannot]):\n",
        "        move_files_to_des(ls_ext,ls_dest)\n",
        "\n",
        "\n",
        "\n",
        "  import os.path as osp\n",
        "  import mmcv\n",
        "  from tools.data.textdet.bid_converter import collect_files,collect_annotations,split_train_val_list,convert_annotations\n",
        "\n",
        "  preserve_vertical=True\n",
        "  nproc=10\n",
        "  format='jsonl'\n",
        "  val_ratio=0.2\n",
        "  root_path =root\n",
        "  with mmcv.Timer(print_tmpl='It takes {}s to convert BID annotation'):\n",
        "      files = collect_files(\n",
        "          osp.join(root_path, 'imgs'), osp.join(root_path, 'annotations'))\n",
        "      image_infos = collect_annotations(files, nproc=nproc)\n",
        "      if val_ratio:\n",
        "          image_infos = split_train_val_list(image_infos, val_ratio)\n",
        "          splits = ['training', 'val']\n",
        "      else:\n",
        "          image_infos = [image_infos]\n",
        "          splits = ['training']\n",
        "      for i, split in enumerate(splits):\n",
        "          convert_annotations(\n",
        "              image_infos[i],\n",
        "              osp.join(root_path, 'instances_' + split + '.json'))\n",
        "          \n",
        "  # Step3: - Step3: Generate instances_training.json and instances_val.json (optional). Since the original dataset doesn’t have a validation set, you may specify --val-ratio to split the dataset. E.g., if val-ratio is 0.2, then 20% of the data are left out as the validation set in this example.\n",
        "\n",
        "  # python tools/data/textdet/bid_converter.py PATH/TO/BID --nproc 4\n",
        "\n",
        "  # After running the above codes, the directory structure should be as follows:\n",
        "\n",
        "  # │── BID\n",
        "  # │   ├── annotations\n",
        "  # │   ├── imgs\n",
        "  # │   ├── instances_training.json\n",
        "  # │   └── instances_val.json (optional)\n",
        "\n",
        "                \n",
        "\n",
        "\n",
        "        \n",
        "    if cleanup:\n",
        "        logging.info ('Cleaning up')\n",
        "        move_files(os.path.join(root,'vietnamese','labels'),dannot)\n",
        "\n",
        "bid('/content/detection') # Yet to check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-YGMjV3UC4X"
      },
      "source": [
        "# ArT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZuF2BDLQuDk"
      },
      "source": [
        "## [Text Recognition](https://mmocr.readthedocs.io/en/latest/datasets/recog.html#art)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zmq86HVSSJ7"
      },
      "outputs": [],
      "source": [
        "def art(npath,cleanup=False):\n",
        "\n",
        "\n",
        "  # Recognition\n",
        "  root=os.path.join(npath,'art')\n",
        "  dannot=os.path.join(root,'annotations')\n",
        "\n",
        "  dcrop=os.path.join(root,'crops')\n",
        "\n",
        "  dpath=dict(dt_img=dict(URL = 'https://dataset-bj.cdn.bcebos.com/art/train_task2_images.tar.gz',\n",
        "                         fpath=os.path.join(root,'train_task2_images.tar.gz')),\n",
        "             lbl=dict(URL = 'https://dataset-bj.cdn.bcebos.com/art/train_task2_labels.json',\n",
        "                         fpath=os.path.join(root,'train_task2_labels.json'))\n",
        "            )\n",
        "  for dp in ([root,dannot,dcrop]):\n",
        "    ch_make_folder(dp)\n",
        "\n",
        "\n",
        "  logging.info ('It may take sometime to extract 439 Mb tar.gz')\n",
        "\n",
        "  for dp in (['dt_img','lbl']):\n",
        "    check_dw(dpath[dp]['fpath'],dpath[dp]['URL'])\n",
        "\n",
        "  logging.info ('It may take sometime to extract 439 Mb tar.gzp')\n",
        "  shutil.unpack_archive(dpath['dt_img']['fpath'],root)\n",
        "  os.rename(os.path.join(root,'train_task2_images'), os.path.join(root,'imgs'))\n",
        "\n",
        "  \n",
        "  shutil.move(os.path.join(root,'train_task2_labels.json'),\n",
        "              os.path.join(dannot,'train_task2_labels.json'))\n",
        "  \n",
        "\n",
        "  root_path = root\n",
        "  preserve_vertical=True\n",
        "  nproc=10\n",
        "  format='jsonl'\n",
        "  val_ratio=0.2\n",
        "\n",
        "  from tools.data.textrecog.art_converter import convert_art\n",
        "\n",
        "\n",
        "  print('Processing training set...')\n",
        "  convert_art(\n",
        "      root_path=root_path,\n",
        "      split='train',\n",
        "      ratio=val_ratio,\n",
        "      format=format)\n",
        "  if val_ratio > 0:\n",
        "      print('Processing validation set...')\n",
        "      convert_art(\n",
        "          root_path=root_path,\n",
        "          split='val',\n",
        "          ratio=val_ratio,\n",
        "          format=format)\n",
        "  print('Finish')\n",
        "\n",
        "\n",
        "  if cleanup:\n",
        "    logging.info ('Cleaning up')\n",
        "    os.remove(dpath['dt_img']['fpath'])\n",
        "# │── art\n",
        "# │   ├── crops\n",
        "# │   ├── train_label.jsonl\n",
        "# │   └── val_label.jsonl (optional)\n",
        "art('/content')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj5KWAldQ3Tz"
      },
      "source": [
        "##[Text Detection](https://mmocr.readthedocs.io/en/latest/datasets/det.html#art)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FqtJ2wGXL9G",
        "outputId": "b9a6c24f-df4a-48c1-d34b-c00946410ab0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:It may take sometime to extract 439 Mb tar.gz\n",
            "INFO:root:It may take sometime to extract 6.81 Gb zip\n"
          ]
        }
      ],
      "source": [
        "def art(npath,cleanup=False):\n",
        "\n",
        "\n",
        "\n",
        "  root=os.path.join(npath,'art')\n",
        "  dannot=os.path.join(root,'annotations')\n",
        "  dpath=dict(dt_img=dict(URL = 'https://dataset-bj.cdn.bcebos.com/art/train_images.tar.gz',\n",
        "                         fpath=os.path.join(root,'train_images.tar.gz')),\n",
        "             lbl=dict(URL = 'https://dataset-bj.cdn.bcebos.com/art/train_labels.json',\n",
        "                         fpath=os.path.join(root,'train_labels.json'))\n",
        "            )\n",
        "  for dp in ([root,dannot,dcrop]):\n",
        "    ch_make_folder(dp)\n",
        "\n",
        "\n",
        "  logging.info ('It may take sometime to extract 439 Mb tar.gz')\n",
        "\n",
        "  for dp in (['dt_img','lbl']):\n",
        "    check_dw(dpath[dp]['fpath'],dpath[dp]['URL'])\n",
        "\n",
        "  logging.info ('It may take sometime to extract 6.81 Gb zip')\n",
        "  shutil.unpack_archive(dpath['dt_img']['fpath'],root)\n",
        "  os.rename(os.path.join(root,'train_images'), os.path.join(root,'imgs')) # The diffrent between recog and detection\n",
        "\n",
        "  shutil.move(dpath['lbl']['fpath'],dannot)\n",
        "  \n",
        "\n",
        "  import os.path as osp\n",
        "\n",
        "  from tools.data.textdet.art_converter import collect_art_info, convert_annotations\n",
        "\n",
        "  root_path = root\n",
        "  val_ratio=0.2\n",
        "  print('Processing training set...')\n",
        "  training_infos = collect_art_info(root_path, 'train', val_ratio)\n",
        "  convert_annotations(training_infos,\n",
        "                      osp.join(root_path, 'instances_training.json'))\n",
        "  if val_ratio > 0:\n",
        "      print('Processing validation set...')\n",
        "      val_infos = collect_art_info(root_path, 'val', val_ratio)\n",
        "      convert_annotations(val_infos, osp.join(root_path,\n",
        "                                              'instances_val.json'))\n",
        "  print('Finish')\n",
        "\n",
        "\n",
        "  # Annotations of ArT test split is not publicly available, split a validation set by adding --val-ratio 0.2\n",
        "  # python tools/data/textdet/art_converter.py PATH/TO/art --nproc 4\n",
        "\n",
        "  # After running the above codes, the directory structure should be as follows:\n",
        "\n",
        "  # │── art\n",
        "  # │   ├── annotations\n",
        "  # │   ├── imgs\n",
        "  # │   ├── instances_training.json\n",
        "  # │   └── instances_val.json (optional)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # if cleanup:\n",
        "  #   logging.info ('Cleaning up')\n",
        "  #   os.remove(dpath['dt_img']['fpath'])\n",
        "\n",
        "art('/content/detection/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he1msMAxZ5Vk",
        "outputId": "6e5cbaf2-59b6-48e2-ee6b-74509d295db0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing training set...\n",
            "training #4482, val #1121\n",
            "1000/4482\n",
            "2000/4482\n",
            "3000/4482\n",
            "4000/4482\n",
            "Processing validation set...\n",
            "training #4482, val #1121\n",
            "1000/1121\n",
            "Finish\n"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3UvJEVTYKHq"
      },
      "source": [
        "# CTW1500\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1ONjA-vRIxj"
      },
      "source": [
        "## [Text Detection](https://mmocr.readthedocs.io/en/latest/datasets/det.html#ctw1500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyx1wcQ_aeRC"
      },
      "outputs": [],
      "source": [
        "def ctw1500(npath,cleanup=False):\n",
        "\n",
        "\n",
        "\n",
        "  root=os.path.join(npath,'ctw1500')\n",
        "  dtr=os.path.join(root,'training')\n",
        "  dts=os.path.join(root,'test')\n",
        "\n",
        "  dpath=dict(lbl_tr=dict(URL = 'https://universityofadelaide.box.com/shared/static/jikuazluzyj4lq6umzei7m2ppmt3afyw.zip',\n",
        "                         fpath=os.path.join(root,'train_labels.zip')),\n",
        "             lbl_ts=dict(URL = 'https://cloudstor.aarnet.edu.au/plus/s/uoeFl0pCN9BOCN5/download',\n",
        "                         fpath=os.path.join(root,'test_labels.zip')),\n",
        "             dt_tr=dict(URL = 'https://universityofadelaide.box.com/shared/static/py5uwlfyyytbb2pxzq9czvu6fuqbjdh8.zip',\n",
        "                         fpath=os.path.join(root,'train_images.zip')),\n",
        "             dt_ts=dict(URL = 'https://universityofadelaide.box.com/shared/static/t4w48ofnqkdw7jyc4t11nsukoeqk9c3d.zip',\n",
        "                         fpath=os.path.join(root,'test_images.zip'))\n",
        "            )\n",
        "  for dp in ([root,dtr,dts]):\n",
        "    ch_make_folder(dp)\n",
        "\n",
        "\n",
        "  logging.info ('It may take sometime to extract 439 Mb tar.gz')\n",
        "  for dp in (['lbl_tr','lbl_ts','dt_tr','dt_ts']):\n",
        "    check_dw(dpath[dp]['fpath'],dpath[dp]['URL'])\n",
        "\n",
        "\n",
        "  logging.info ('It may take sometime to extract 6.81 Gb zip')\n",
        "  for dp,fdir in zip(['lbl_tr','lbl_ts','dt_tr','dt_ts'],\n",
        "                [dtr,dts,dtr,dts]):\n",
        "    shutil.unpack_archive(dpath[dp]['fpath'],fdir)\n",
        "\n",
        "\n",
        "  if cleanup:\n",
        "    logging.info ('Cleaning up')\n",
        "    for dp in (['lbl_tr','lbl_ts','dt_tr','dt_ts']):\n",
        "      print(dpath[dp]['fpath'])\n",
        "      os.remove(dpath[dp]['fpath'])\n",
        "\n",
        "# ├── ctw1500\n",
        "# │   ├── imgs\n",
        "# │   ├── annotations\n",
        "# │   ├── instances_training.json\n",
        "# │   └── instances_val.json\n",
        "ctw1500('/content')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGpgfGZoYalc"
      },
      "source": [
        "# CurvedSynText150k (KIV)\n",
        "\n",
        "Since the file is to large, about 32 Gb, adviseable to first download and store in the folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79TStxz5n7f_"
      },
      "source": [
        "## [Text Detection](https://mmocr.readthedocs.io/en/latest/datasets/det.html#curvedsyntext150k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pu5B07TMYowm"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "def curvedsyntext(npath,cleanup=False):\n",
        "\n",
        "\n",
        "  Warning.warn('WIP: Still find an alternative on automatically download from Google Drive')\n",
        "  root=os.path.join(npath,'curvedsyntext')\n",
        "  dtr=os.path.join(root,'training')\n",
        "  dts=os.path.join(root,'test')\n",
        "\n",
        "  dpath=dict(dt_1=dict(URL = 'https://drive.google.com/open?id=1OSJ-zId2h3t_-I7g_wUkrK-VqQy153Kj&authuser=0',\n",
        "                         fpath=os.path.join(root,'syntext1.zip ')),\n",
        "             dt_2=dict(URL = 'https://drive.google.com/open?id=1EzkcOlIgEp5wmEubvHb7-J5EImHExYgY&authuser=0',\n",
        "                         fpath=os.path.join(root,'syntext2.zip ')),\n",
        "            )\n",
        "  for dp in ([root,dtr,dts]):\n",
        "    ch_make_folder(dp)\n",
        "\n",
        "  import gdown\n",
        "  for dp in (['dt_1','dt_2']):\n",
        "    logging.info ('It may take sometime to download 32 Gb zip file from Google Drive')\n",
        "    if not isfile(dpath[dp]['fpath']):\n",
        "        gdown.download(dpath[dp]['URL'], dpath[dp]['fpath'], quiet=False)\n",
        "\n",
        "\n",
        "\n",
        "  logging.info ('It may take sometime to extract 6.81 Gb zip')\n",
        "  for dp,fdir in zip(['dt_1','dt_2'],\n",
        "                [dtr,dts]):\n",
        "    shutil.unpack_archive(dpath[dp]['fpath'],fdir)\n",
        "\n",
        "\n",
        "  if cleanup:\n",
        "    logging.info ('Cleaning up')\n",
        "    for dp in (['lbl_tr','lbl_ts','dt_tr','dt_ts']):\n",
        "      print(dpath[dp]['fpath'])\n",
        "      os.remove(dpath[dp]['fpath'])\n",
        "\n",
        "# ├── CurvedSynText150k\n",
        "# │   ├── syntext_word_eng\n",
        "# │   ├── emcs_imgs\n",
        "# │   └── instances_training.json\n",
        "curvedsyntext('/content')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ei_5LsIGYh_m"
      },
      "source": [
        "# SROIE\n",
        "\n",
        "warning.warn('WIP since need to download from Google Drive')\n",
        "\n",
        "Links\n",
        "\n",
        "Main page\n",
        "https://rrc.cvc.uab.es/?ch=13&com=downloads\n",
        "\n",
        "\n",
        "https://rrc.cvc.uab.es/?com=downloads&action=download&ch=13&f=aHR0cHM6Ly9kcml2ZS5nb29nbGUuY29tL29wZW4/aWQ9MVNoSXROV1h5aVkxdEZETTVXMDJiY2VIdUpqeWVlSmwy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "https://rrc.cvc.uab.es/?com=downloads&action=download&ch=13&f=aHR0cHM6Ly9kcml2ZS5nb29nbGUuY29tL29wZW4/aWQ9MVNoSXROV1h5aVkxdEZETTVXMDJiY2VIdUpqeWVlSmwy\n",
        "\n",
        "\n",
        "https://rrc.cvc.uab.es/?com=downloads&action=download&ch=13&f=aHR0cHM6Ly9ycmMuY3ZjLnVhYi5lcy9kb3dubG9hZHMvU1JPSUVfdGVzdF9pbWFnZXNfdGFza18zLnppcA==\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC2o79BBRhWn"
      },
      "source": [
        "## [Text Detection](https://mmocr.readthedocs.io/en/latest/datasets/det.html#sroie)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMBi9xaVpvfi"
      },
      "outputs": [],
      "source": [
        "warning.warn('WIP since need to download from Google Drive')\n",
        "\n",
        "Links\n",
        "\n",
        "Main page\n",
        "https://rrc.cvc.uab.es/?ch=13&com=downloads\n",
        "\n",
        "\n",
        "https://rrc.cvc.uab.es/?com=downloads&action=download&ch=13&f=aHR0cHM6Ly9kcml2ZS5nb29nbGUuY29tL29wZW4/aWQ9MVNoSXROV1h5aVkxdEZETTVXMDJiY2VIdUpqeWVlSmwy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDvLKtYIYnm4"
      },
      "source": [
        "# KAIST (KOREAN) NA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwcu4rydYpvC"
      },
      "source": [
        "# MTWI (Chinese) NA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kTJOcBKYtEh"
      },
      "source": [
        "# ReCTS\n",
        "\n",
        "obust Reading Challenge on Reading Chinese Text on Signboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKb9oKjvYvjy"
      },
      "source": [
        "# IIIT-ILST\n",
        "\n",
        "\n",
        "Devanagari ,Malayalam, Telugu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCVeHzCmrbMG"
      },
      "outputs": [],
      "source": [
        "https://iiitaphyd-my.sharepoint.com/personal/minesh_mathew_research_iiit_ac_in/_layouts/15/download.aspx?UniqueId=dffd4198%2Dbcdc%2D4994%2D990d%2D682525da47dd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRwh7vjMrXMK",
        "outputId": "ebab45f5-0104-4d08-f45a-8293115db3e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-06-12 06:50:28--  https://iiitaphyd-my.sharepoint.com/personal/minesh_mathew_research_iiit_ac_in/_layouts/15/download.aspx?UniqueId=dffd4198%2Dbcdc%2D4994%2D990d%2D682525da47dd\n",
            "Resolving iiitaphyd-my.sharepoint.com (iiitaphyd-my.sharepoint.com)... 13.107.136.9, 13.107.138.9\n",
            "Connecting to iiitaphyd-my.sharepoint.com (iiitaphyd-my.sharepoint.com)|13.107.136.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 403 Forbidden\n",
            "2022-06-12 06:50:29 ERROR 403: Forbidden.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://iiitaphyd-my.sharepoint.com/personal/minesh_mathew_research_iiit_ac_in/_layouts/15/download.aspx?UniqueId=dffd4198%2Dbcdc%2D4994%2D990d%2D682525da47dd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXFbuwS5YzzC"
      },
      "source": [
        "# RCTW\n",
        "\n",
        "ICDAR2017 Competition on Reading Chinese Text in the Wild"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoL5_DIhY1z6"
      },
      "source": [
        "# HierText\n",
        "\n",
        "ICDAR2017 Competition on Reading Chinese Text in the Wild\n",
        "\n",
        "\n",
        "Step2: Clone HierText repo to get annotations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o22xJRjoSYrM"
      },
      "source": [
        "# IMGUR (TBD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZOP_YcgSgK-"
      },
      "outputs": [],
      "source": [
        "def imgur(npath):\n",
        "\n",
        "\n",
        "\n",
        "  root=os.path.join(npath,'imgur')\n",
        "  dannot=os.path.join(root,'annotations')\n",
        "  dimg=os.path.join(root,'imgs')\n",
        "\n",
        "  dpath=dict(dt_img=dict(URL = 'XXX',\n",
        "                         fpath=os.path.join(root,'XX'))\n",
        "            )\n",
        "  \n",
        "\n",
        "  for dp in ([root,dannot,dimg]):\n",
        "    ch_make_folder(dp)\n",
        "\n",
        "  logging.info ('Download images from imgur.com. This may take SEVERAL HOURS!')\n",
        " \n",
        "imgur('/content')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP8zR-INrMhA"
      },
      "source": [
        "# Other"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDozyBRtGe-u"
      },
      "outputs": [],
      "source": [
        "# !wget https://rrc.cvc.uab.es/downloads/ch9_training_images.zip --no-check-certificate\n",
        "\n",
        "\n",
        "def check_dw(sfile,url):\n",
        "  if not isfile(sfile):\n",
        "      logging.info(f'The file {sfile} is not availaible, downloading from {url}')\n",
        "      wget.download(url, out=sfile)\n",
        "      # r = requests.get(url, verify=False,stream=True)  \n",
        "      # with open(sfile, 'wb') as f:\n",
        "      #   f.write(r.content)\n",
        "check_dw('ch9_training_images.zip','https://rrc.cvc.uab.es/downloads/ch9_training_images.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PL-RwvufC4k"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import requests\n",
        "def download(url, filename):\n",
        "    with open(filename, 'wb') as f:\n",
        "        response = requests.get(url, stream=True)\n",
        "        total = response.headers.get('content-length')\n",
        "\n",
        "        if total is None:\n",
        "            f.write(response.content)\n",
        "        else:\n",
        "            downloaded = 0\n",
        "            total = int(total)\n",
        "            for data in response.iter_content(chunk_size=max(int(total/1000), 1024*1024)):\n",
        "                downloaded += len(data)\n",
        "                f.write(data)\n",
        "                done = int(50*downloaded/total)\n",
        "                sys.stdout.write('\\r[{}{}]'.format('█' * done, '.' * (50-done)))\n",
        "                sys.stdout.flush()\n",
        "    sys.stdout.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNKuHz2Gfcde"
      },
      "outputs": [],
      "source": [
        "\n",
        "url='https://download.openmmlab.com/mmocr/data/mixture/Syn90k/label.txt'\n",
        "download(url, 'label.txt')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "HcskSXOXbiX0",
        "uIqP0Hmtp55Z",
        "3vPW8mcOptW5",
        "pNn-07bP9-X1",
        "-k092iMMskro",
        "W1ONjA-vRIxj"
      ],
      "name": "helper_download_det_dataset",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "12ZWCWIdxeUSw0F5y6WUiGDc6mbI-kV24",
      "authorship_tag": "ABX9TyMjIHxbfHKNMmNz48OQHmbD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}