{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "how_to_load_base_config.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/balandongiv/mmocr_tutorial/blob/main/how_to_load_base_config.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MMOCR Tutorial\n",
        "\n",
        "Welcome to MMOCR! This is the **unofficial** colab tutorial for using MMOCR. In this tutorial, you will learn how to\n",
        "\n",
        "- Make config"
      ],
      "metadata": {
        "id": "U-Xyj4cQrEQ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install MMOCR"
      ],
      "metadata": {
        "id": "Sfvz1sywQ9_4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Dependencies "
      ],
      "metadata": {
        "id": "Tw7u_baQpEUs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "%cd ..\n",
        "# Install mmcv-full thus we could use CUDA operators\n",
        "!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu113/torch1.11.0/index.html\n",
        "\n",
        "# Install mmdetection\n",
        "!pip install mmdet\n",
        "\n",
        "# # Install mmocr\n",
        "!git clone https://github.com/open-mmlab/mmocr.git\n",
        "%cd mmocr\n",
        "!pip install -r requirements.txt\n",
        "!pip install -v -e .\n",
        "\n",
        "!pip install wget"
      ],
      "outputs": [],
      "metadata": {
        "id": "DwDY3puNNmhe",
        "tags": [
          "outputPrepend"
        ]
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Installed Dependencies Versions"
      ],
      "metadata": {
        "id": "DY64JCc0pEUu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import mmcv\n",
        "import matplotlib.pyplot as plt \n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import wget\n",
        "\n",
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check MMDetection installation\n",
        "import mmdet\n",
        "print(mmdet.__version__)\n",
        "\n",
        "# Check mmcv installation\n",
        "import mmcv\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(mmcv.__version__)\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())\n",
        "\n",
        "# Check mmocr installation\n",
        "import mmocr\n",
        "print(mmocr.__version__)\n",
        "\n",
        "%cd /mmocr/\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "JABQfPwQN52g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load exisiting config\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nYon41X7RTOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "!gdown --folder https://drive.google.com/drive/folders/1Lk7O4bg3oX6JRVEzVptf3P_hFFQSfxNK?usp=sharing -O custom_cfg"
      ],
      "metadata": {
        "id": "kCl0oTQHsvnJ",
        "outputId": "384e2310-b95a-4a56-bde0-e1e3756b543a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder list\n",
            "Processing file 17sx7GvwGSvU0EiilnlX0BE5hTpfhCUJc custom_config.py\n",
            "Retrieving folder list completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17sx7GvwGSvU0EiilnlX0BE5hTpfhCUJc\n",
            "To: /mmocr/custom_cfg/custom_config.py\n",
            "100% 2.25k/2.25k [00:00<00:00, 4.80MB/s]\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "_base_ = [\n",
        "    '/mmocr/configs/_base_/default_runtime.py',\n",
        "    '/mmocr/configs/_base_/recog_models/sar.py',\n",
        "    '/mmocr/configs/_base_/schedules/schedule_adam_step_5e.py',\n",
        "    '/mmocr/configs/_base_/recog_pipelines/sar_pipeline.py',\n",
        "]\n",
        "\n",
        "dataset_type = 'OCRDataset'\n",
        "\n",
        "# Location where the annotation and crop images are being stored\n",
        "root='/mmocr/tests/data/ocr_toy_dataset'\n",
        "\n",
        "\n",
        "img_prefix =os.path.join(root,'imgs')\n",
        "\n",
        "\n",
        "train_anno_file1 = os.path.join(root,'label.txt')\n",
        "\n",
        "\n",
        "\n",
        "train_datasets1 = dict(\n",
        "    type='OCRDataset',\n",
        "    img_prefix=img_prefix,\n",
        "    ann_file=train_anno_file1,\n",
        "    loader=dict(\n",
        "        type='AnnFileLoader',\n",
        "        repeat=20,\n",
        "        file_format='txt',\n",
        "        parser=dict(\n",
        "            type='LineStrParser',\n",
        "            keys=['filename', 'text'],\n",
        "            keys_idx=[0, 1],\n",
        "            separator=' ')),\n",
        "    pipeline=None,\n",
        "    test_mode=False)\n",
        "\n",
        "\n",
        "train_datasets1 = dict(\n",
        "    type='OCRDataset',\n",
        "    img_prefix=img_prefix,\n",
        "    ann_file=train_anno_file1,\n",
        "    loader=dict(\n",
        "        type='AnnFileLoader',\n",
        "        repeat=20,\n",
        "        file_format='txt',\n",
        "        parser=dict(\n",
        "            type='LineStrParser',\n",
        "            keys=['filename', 'text'],\n",
        "            keys_idx=[0, 1],\n",
        "            separator=' ')),\n",
        "    pipeline=None,\n",
        "    test_mode=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# For time being, assume the setting for training and validation is the same, though practically we can separate both testing sets\n",
        "\n",
        "\n",
        "\n",
        "train_list = [train_datasets1]\n",
        "\n",
        "# For demonstration purpose, we assume the train and validation list is the same\n",
        "test_list = [train_datasets1]\n",
        "\n",
        "\n",
        "train_pipeline = {{_base_.train_pipeline}}\n",
        "test_pipeline = {{_base_.test_pipeline}}\n",
        "\n",
        "data = dict(\n",
        "    samples_per_gpu=64,\n",
        "    workers_per_gpu=2,\n",
        "    val_dataloader=dict(samples_per_gpu=1),\n",
        "    test_dataloader=dict(samples_per_gpu=1),\n",
        "    train=dict(\n",
        "        type='UniformConcatDataset',\n",
        "        datasets=train_list,\n",
        "        pipeline=train_pipeline),\n",
        "    val=dict(\n",
        "        type='UniformConcatDataset',\n",
        "        datasets=test_list,\n",
        "        pipeline=test_pipeline),\n",
        "    test=dict(\n",
        "        type='UniformConcatDataset',\n",
        "        datasets=test_list,\n",
        "        pipeline=test_pipeline))\n",
        "\n",
        "evaluation = dict(interval=1, metric='acc')"
      ],
      "metadata": {
        "id": "uvt-ugjKoRPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let create cfg"
      ],
      "metadata": {
        "id": "FDZBBMrpuTcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tLPkYLUauVCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mmcv import Config\n",
        "\n",
        "cfg = Config.fromfile('/mmocr/custom_cfg/custom_config.py')"
      ],
      "metadata": {
        "id": "9eFrDIZsub5Q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Config:\\n{cfg.pretty_text}')"
      ],
      "metadata": {
        "id": "HKvweSo6uv5N",
        "outputId": "e0283296-b723-43cf-cabc-556b29e0b3f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config:\n",
            "log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "load_from = None\n",
            "resume_from = None\n",
            "workflow = [('train', 1)]\n",
            "opencv_num_threads = 0\n",
            "mp_start_method = 'fork'\n",
            "label_convertor = dict(\n",
            "    type='AttnConvertor', dict_type='DICT90', with_unknown=True)\n",
            "model = dict(\n",
            "    type='SARNet',\n",
            "    backbone=dict(type='ResNet31OCR'),\n",
            "    encoder=dict(\n",
            "        type='SAREncoder', enc_bi_rnn=False, enc_do_rnn=0.1, enc_gru=False),\n",
            "    decoder=dict(\n",
            "        type='ParallelSARDecoder',\n",
            "        enc_bi_rnn=False,\n",
            "        dec_bi_rnn=False,\n",
            "        dec_do_rnn=0,\n",
            "        dec_gru=False,\n",
            "        pred_dropout=0.1,\n",
            "        d_k=512,\n",
            "        pred_concat=True),\n",
            "    loss=dict(type='SARLoss'),\n",
            "    label_convertor=dict(\n",
            "        type='AttnConvertor', dict_type='DICT90', with_unknown=True),\n",
            "    max_seq_len=30)\n",
            "optimizer = dict(type='Adam', lr=0.001)\n",
            "optimizer_config = dict(grad_clip=None)\n",
            "lr_config = dict(policy='step', step=[3, 4])\n",
            "runner = dict(type='EpochBasedRunner', max_epochs=5)\n",
            "checkpoint_config = dict(interval=1)\n",
            "img_norm_cfg = dict(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='ResizeOCR',\n",
            "        height=48,\n",
            "        min_width=48,\n",
            "        max_width=160,\n",
            "        keep_aspect_ratio=True,\n",
            "        width_downsample_ratio=0.25),\n",
            "    dict(type='ToTensorOCR'),\n",
            "    dict(type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
            "    dict(\n",
            "        type='Collect',\n",
            "        keys=['img'],\n",
            "        meta_keys=[\n",
            "            'filename', 'ori_shape', 'resize_shape', 'text', 'valid_ratio'\n",
            "        ])\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiRotateAugOCR',\n",
            "        rotate_degrees=[0, 90, 270],\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='ResizeOCR',\n",
            "                height=48,\n",
            "                min_width=48,\n",
            "                max_width=160,\n",
            "                keep_aspect_ratio=True,\n",
            "                width_downsample_ratio=0.25),\n",
            "            dict(type='ToTensorOCR'),\n",
            "            dict(\n",
            "                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,\n",
            "                                                                0.5]),\n",
            "            dict(\n",
            "                type='Collect',\n",
            "                keys=['img'],\n",
            "                meta_keys=[\n",
            "                    'filename', 'ori_shape', 'resize_shape', 'valid_ratio',\n",
            "                    'img_norm_cfg', 'ori_filename', 'img_shape'\n",
            "                ])\n",
            "        ])\n",
            "]\n",
            "dataset_type = 'OCRDataset'\n",
            "root = '/mmocr/tests/data/ocr_toy_dataset'\n",
            "img_prefix = '/mmocr/tests/data/ocr_toy_dataset/imgs'\n",
            "train_anno_file1 = '/mmocr/tests/data/ocr_toy_dataset/label.txt'\n",
            "train_datasets1 = dict(\n",
            "    type='OCRDataset',\n",
            "    img_prefix='/mmocr/tests/data/ocr_toy_dataset/imgs',\n",
            "    ann_file='/mmocr/tests/data/ocr_toy_dataset/label.txt',\n",
            "    loader=dict(\n",
            "        type='AnnFileLoader',\n",
            "        repeat=20,\n",
            "        file_format='txt',\n",
            "        parser=dict(\n",
            "            type='LineStrParser',\n",
            "            keys=['filename', 'text'],\n",
            "            keys_idx=[0, 1],\n",
            "            separator=' ')),\n",
            "    pipeline=None,\n",
            "    test_mode=False)\n",
            "train_list = [\n",
            "    dict(\n",
            "        type='OCRDataset',\n",
            "        img_prefix='/mmocr/tests/data/ocr_toy_dataset/imgs',\n",
            "        ann_file='/mmocr/tests/data/ocr_toy_dataset/label.txt',\n",
            "        loader=dict(\n",
            "            type='AnnFileLoader',\n",
            "            repeat=20,\n",
            "            file_format='txt',\n",
            "            parser=dict(\n",
            "                type='LineStrParser',\n",
            "                keys=['filename', 'text'],\n",
            "                keys_idx=[0, 1],\n",
            "                separator=' ')),\n",
            "        pipeline=None,\n",
            "        test_mode=False)\n",
            "]\n",
            "test_list = [\n",
            "    dict(\n",
            "        type='OCRDataset',\n",
            "        img_prefix='/mmocr/tests/data/ocr_toy_dataset/imgs',\n",
            "        ann_file='/mmocr/tests/data/ocr_toy_dataset/label.txt',\n",
            "        loader=dict(\n",
            "            type='AnnFileLoader',\n",
            "            repeat=20,\n",
            "            file_format='txt',\n",
            "            parser=dict(\n",
            "                type='LineStrParser',\n",
            "                keys=['filename', 'text'],\n",
            "                keys_idx=[0, 1],\n",
            "                separator=' ')),\n",
            "        pipeline=None,\n",
            "        test_mode=False)\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=64,\n",
            "    workers_per_gpu=2,\n",
            "    val_dataloader=dict(samples_per_gpu=1),\n",
            "    test_dataloader=dict(samples_per_gpu=1),\n",
            "    train=dict(\n",
            "        type='UniformConcatDataset',\n",
            "        datasets=[\n",
            "            dict(\n",
            "                type='OCRDataset',\n",
            "                img_prefix='/mmocr/tests/data/ocr_toy_dataset/imgs',\n",
            "                ann_file='/mmocr/tests/data/ocr_toy_dataset/label.txt',\n",
            "                loader=dict(\n",
            "                    type='AnnFileLoader',\n",
            "                    repeat=20,\n",
            "                    file_format='txt',\n",
            "                    parser=dict(\n",
            "                        type='LineStrParser',\n",
            "                        keys=['filename', 'text'],\n",
            "                        keys_idx=[0, 1],\n",
            "                        separator=' ')),\n",
            "                pipeline=None,\n",
            "                test_mode=False)\n",
            "        ],\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='ResizeOCR',\n",
            "                height=48,\n",
            "                min_width=48,\n",
            "                max_width=160,\n",
            "                keep_aspect_ratio=True,\n",
            "                width_downsample_ratio=0.25),\n",
            "            dict(type='ToTensorOCR'),\n",
            "            dict(\n",
            "                type='NormalizeOCR', mean=[0.5, 0.5, 0.5], std=[0.5, 0.5,\n",
            "                                                                0.5]),\n",
            "            dict(\n",
            "                type='Collect',\n",
            "                keys=['img'],\n",
            "                meta_keys=[\n",
            "                    'filename', 'ori_shape', 'resize_shape', 'text',\n",
            "                    'valid_ratio'\n",
            "                ])\n",
            "        ]),\n",
            "    val=dict(\n",
            "        type='UniformConcatDataset',\n",
            "        datasets=[\n",
            "            dict(\n",
            "                type='OCRDataset',\n",
            "                img_prefix='/mmocr/tests/data/ocr_toy_dataset/imgs',\n",
            "                ann_file='/mmocr/tests/data/ocr_toy_dataset/label.txt',\n",
            "                loader=dict(\n",
            "                    type='AnnFileLoader',\n",
            "                    repeat=20,\n",
            "                    file_format='txt',\n",
            "                    parser=dict(\n",
            "                        type='LineStrParser',\n",
            "                        keys=['filename', 'text'],\n",
            "                        keys_idx=[0, 1],\n",
            "                        separator=' ')),\n",
            "                pipeline=None,\n",
            "                test_mode=False)\n",
            "        ],\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiRotateAugOCR',\n",
            "                rotate_degrees=[0, 90, 270],\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='ResizeOCR',\n",
            "                        height=48,\n",
            "                        min_width=48,\n",
            "                        max_width=160,\n",
            "                        keep_aspect_ratio=True,\n",
            "                        width_downsample_ratio=0.25),\n",
            "                    dict(type='ToTensorOCR'),\n",
            "                    dict(\n",
            "                        type='NormalizeOCR',\n",
            "                        mean=[0.5, 0.5, 0.5],\n",
            "                        std=[0.5, 0.5, 0.5]),\n",
            "                    dict(\n",
            "                        type='Collect',\n",
            "                        keys=['img'],\n",
            "                        meta_keys=[\n",
            "                            'filename', 'ori_shape', 'resize_shape',\n",
            "                            'valid_ratio', 'img_norm_cfg', 'ori_filename',\n",
            "                            'img_shape'\n",
            "                        ])\n",
            "                ])\n",
            "        ]),\n",
            "    test=dict(\n",
            "        type='UniformConcatDataset',\n",
            "        datasets=[\n",
            "            dict(\n",
            "                type='OCRDataset',\n",
            "                img_prefix='/mmocr/tests/data/ocr_toy_dataset/imgs',\n",
            "                ann_file='/mmocr/tests/data/ocr_toy_dataset/label.txt',\n",
            "                loader=dict(\n",
            "                    type='AnnFileLoader',\n",
            "                    repeat=20,\n",
            "                    file_format='txt',\n",
            "                    parser=dict(\n",
            "                        type='LineStrParser',\n",
            "                        keys=['filename', 'text'],\n",
            "                        keys_idx=[0, 1],\n",
            "                        separator=' ')),\n",
            "                pipeline=None,\n",
            "                test_mode=False)\n",
            "        ],\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiRotateAugOCR',\n",
            "                rotate_degrees=[0, 90, 270],\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        type='ResizeOCR',\n",
            "                        height=48,\n",
            "                        min_width=48,\n",
            "                        max_width=160,\n",
            "                        keep_aspect_ratio=True,\n",
            "                        width_downsample_ratio=0.25),\n",
            "                    dict(type='ToTensorOCR'),\n",
            "                    dict(\n",
            "                        type='NormalizeOCR',\n",
            "                        mean=[0.5, 0.5, 0.5],\n",
            "                        std=[0.5, 0.5, 0.5]),\n",
            "                    dict(\n",
            "                        type='Collect',\n",
            "                        keys=['img'],\n",
            "                        meta_keys=[\n",
            "                            'filename', 'ori_shape', 'resize_shape',\n",
            "                            'valid_ratio', 'img_norm_cfg', 'ori_filename',\n",
            "                            'img_shape'\n",
            "                        ])\n",
            "                ])\n",
            "        ]))\n",
            "evaluation = dict(interval=1, metric='acc')\n",
            "\n"
          ]
        }
      ]
    }
  ]
}